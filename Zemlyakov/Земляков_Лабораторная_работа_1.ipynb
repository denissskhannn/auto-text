{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VL_YISip2qbr"
      },
      "source": [
        "**Задание 0. Загрузите необходимые библиотеки**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0YUM4z_92XzR"
      },
      "source": [
        "**Задание 1. Загрузка данных**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hwqI1lLF2j3t"
      },
      "source": [
        "Вставьте текст для обработки согласно вашему варианту"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MR7fi9AAAKYJ",
        "outputId": "be52a0bc-2940-4779-ee69-be0081897da2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (3.9.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (3.8.11)\n",
            "Collecting pymorphy2\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Collecting natasha\n",
            "  Downloading natasha-1.6.0-py3-none-any.whl.metadata (23 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk) (8.3.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk) (1.5.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk) (2025.11.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk) (4.67.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (0.21.1)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy) (25.0)\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy2)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl.metadata (7.0 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl.metadata (2.1 kB)\n",
            "Collecting docopt>=0.6 (from pymorphy2)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting razdel>=0.5.0 (from natasha)\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl.metadata (10.0 kB)\n",
            "Collecting navec>=0.9.0 (from natasha)\n",
            "  Downloading navec-0.10.0-py3-none-any.whl.metadata (21 kB)\n",
            "Collecting slovnet>=0.6.0 (from natasha)\n",
            "  Downloading slovnet-0.6.0-py3-none-any.whl.metadata (34 kB)\n",
            "Collecting yargy>=0.16.0 (from natasha)\n",
            "  Downloading yargy-0.16.0-py3-none-any.whl.metadata (3.5 kB)\n",
            "Collecting ipymarkup>=0.8.0 (from natasha)\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting intervaltree>=3 (from ipymarkup>=0.8.0->natasha)\n",
            "  Downloading intervaltree-3.2.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.41.4)\n",
            "Requirement already satisfied: typing-extensions>=4.14.1 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.15.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.4.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2026.1.4)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (0.23.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy) (7.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy) (3.0.3)\n",
            "Collecting sortedcontainers (from intervaltree>=3->ipymarkup>=0.8.0->natasha)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.4.2->spacy) (2.0.1)\n",
            "Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading natasha-1.6.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Downloading slovnet-0.6.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading yargy-0.16.0-py3-none-any.whl (33 kB)\n",
            "Downloading intervaltree-3.2.1-py2.py3-none-any.whl (25 kB)\n",
            "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Building wheels for collected packages: docopt\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13706 sha256=3a7dec51521346fbcf91780cda24cb1f3b170478a8613e2fd10beed8c41dc736\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/bf/a1/4cee4f7678c68c5875ca89eaccf460593539805c3906722228\n",
            "Successfully built docopt\n",
            "Installing collected packages: sortedcontainers, razdel, pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 intervaltree-3.2.1 ipymarkup-0.9.0 natasha-1.6.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.6.0 sortedcontainers-2.4.0 yargy-0.16.0\n",
            "Collecting ru-core-news-sm==3.8.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/ru_core_news_sm-3.8.0/ru_core_news_sm-3.8.0-py3-none-any.whl (15.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymorphy3>=1.0.0 (from ru-core-news-sm==3.8.0)\n",
            "  Downloading pymorphy3-2.0.6-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting dawg2-python>=0.8.0 (from pymorphy3>=1.0.0->ru-core-news-sm==3.8.0)\n",
            "  Downloading dawg2_python-0.9.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting pymorphy3-dicts-ru (from pymorphy3>=1.0.0->ru-core-news-sm==3.8.0)\n",
            "  Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: setuptools>=68.2.2 in /usr/local/lib/python3.12/dist-packages (from pymorphy3>=1.0.0->ru-core-news-sm==3.8.0) (75.2.0)\n",
            "Downloading pymorphy3-2.0.6-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.9/53.9 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dawg2_python-0.9.0-py3-none-any.whl (9.3 kB)\n",
            "Downloading pymorphy3_dicts_ru-2.4.417150.4580142-py2.py3-none-any.whl (8.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymorphy3-dicts-ru, dawg2-python, pymorphy3, ru-core-news-sm\n",
            "Successfully installed dawg2-python-0.9.0 pymorphy3-2.0.6 pymorphy3-dicts-ru-2.4.417150.4580142 ru-core-news-sm-3.8.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('ru_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk spacy pymorphy2 natasha\n",
        "!python -m spacy download ru_core_news_sm\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "import spacy\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "B2Tsy8T62ZRo"
      },
      "outputs": [],
      "source": [
        "original_text =\"\"\"Квантовая механика — одна из самых загадочных областей современной физики.\n",
        "\n",
        "В мире частиц размером 10^-9 м действуют законы, противоречащие нашей интуиции!\n",
        "\n",
        "Эксперимент с двумя щелями (double-slit experiment) демонстрирует, что электрон может вести себя и как частица, и как волна одновременно.\n",
        "\n",
        "Принцип неопределённости Гейзенберга утверждает: невозможно одновременно точно измерить положение и импульс частицы.\n",
        "\n",
        "Чем точнее мы знаем одно, тем менее определённым становится другое.\n",
        "\n",
        "Уравнение Шрёдингера — ключевая формула квантовой теории — описывает эволюцию волновой функции.\n",
        "\n",
        "Явление \"квантовой запутанности\" (quantum entanglement) Эйнштейн называл \"жутким действием на расстоянии\".\n",
        "\n",
        "В 2023 году китайские учёные установили новый рекорд: им удалось запутать 18 фотонов, что открывает новые горизонты для квантовых компьютеров!\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYmTHvNm2ph6"
      },
      "source": [
        "**Задание 2. Нормализация текста.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XgLHFLVp3Apg"
      },
      "source": [
        "Приведите текст к нижнему регистру, удалите лишние пробелы, переносы строк, спецсимволы, пунктуацию, обработайте цифры."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiyJLZrm3Z8s",
        "outputId": "5ff58752-5345-496e-8cc4-8f6393d3d4c9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "квантовая механика одна из самых загадочных областей современной физики в мире частиц размером м действуют законы противоречащие нашей интуиции эксперимент с двумя щелями double slit experiment демонстрирует что электрон может вести себя и как частица и как волна одновременно принцип неопределённости гейзенберга утверждает невозможно одновременно точно измерить положение и импульс частицы чем точнее мы знаем одно тем менее определённым становится другое уравнение шрёдингера ключевая формула квантовой теории описывает эволюцию волновой функции явление квантовой запутанности quantum entanglement эйнштейн называл жутким действием на расстоянии в году китайские учёные установили новый рекорд им удалось запутать фотонов что открывает новые горизонты для квантовых компьютеров\n"
          ]
        }
      ],
      "source": [
        "# ваш код\n",
        "import re\n",
        "text = original_text.lower()\n",
        "text = re.sub(r'\\s+', ' ', text)\n",
        "text = re.sub(r'\\d+', ' ', text)\n",
        "text = re.sub(r'\\n', ' ', text)\n",
        "text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "text = re.sub(r'[^\\w\\s]', '', text)\n",
        "text = \" \".join(text.split())\n",
        "\n",
        "print(text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6evm-5d3dPD"
      },
      "source": [
        "**Задание 3. Токенизация**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O90JD4L83gbj"
      },
      "source": [
        "Токенизируйте текст."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjGIQM3F3udR",
        "outputId": "73088da3-4cff-4644-f977-a1bac9001299"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['квантовая', 'механика', 'одна', 'из', 'самых', 'загадочных', 'областей', 'современной', 'физики', 'в', 'мире', 'частиц', 'размером', 'м', 'действуют', 'законы', 'противоречащие', 'нашей', 'интуиции', 'эксперимент', 'с', 'двумя', 'щелями', 'double', 'slit', 'experiment', 'демонстрирует', 'что', 'электрон', 'может', 'вести', 'себя', 'и', 'как', 'частица', 'и', 'как', 'волна', 'одновременно', 'принцип', 'неопределённости', 'гейзенберга', 'утверждает', 'невозможно', 'одновременно', 'точно', 'измерить', 'положение', 'и', 'импульс', 'частицы', 'чем', 'точнее', 'мы', 'знаем', 'одно', 'тем', 'менее', 'определённым', 'становится', 'другое', 'уравнение', 'шрёдингера', 'ключевая', 'формула', 'квантовой', 'теории', 'описывает', 'эволюцию', 'волновой', 'функции', 'явление', 'квантовой', 'запутанности', 'quantum', 'entanglement', 'эйнштейн', 'называл', 'жутким', 'действием', 'на', 'расстоянии', 'в', 'году', 'китайские', 'учёные', 'установили', 'новый', 'рекорд', 'им', 'удалось', 'запутать', 'фотонов', 'что', 'открывает', 'новые', 'горизонты', 'для', 'квантовых', 'компьютеров']\n"
          ]
        }
      ],
      "source": [
        "# ваш код\n",
        "tokens = text.split()\n",
        "print(tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0ED6dCL3vrB"
      },
      "source": [
        "**Задание 4. Удаление стоп-слов**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "awJNjV8y30zn"
      },
      "source": [
        "Выведите 2 списка - 1. Очищенных токенов, 2. Список удаленных стоп-слов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk5XICly_YqC",
        "outputId": "3525a2f4-05be-471f-ae2b-8c6e83e2d70a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "russian_stopwords = set(stopwords.words('russian'))\n",
        "nlp_ru = spacy.load(\"ru_core_news_sm\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9uFV9dG39L2",
        "outputId": "11d501c6-3d3a-4287-eccb-b2f6cba5f675"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['квантовая', 'механика', 'одна', 'самых', 'загадочных', 'областей', 'современной', 'физики', 'мире', 'частиц', 'размером', 'м', 'действуют', 'законы', 'противоречащие', 'нашей', 'интуиции', 'эксперимент', 'двумя', 'щелями', 'double', 'slit', 'experiment', 'демонстрирует', 'электрон', 'вести', 'частица', 'волна', 'одновременно', 'принцип', 'неопределённости', 'гейзенберга', 'утверждает', 'невозможно', 'одновременно', 'точно', 'измерить', 'положение', 'импульс', 'частицы', 'точнее', 'знаем', 'одно', 'менее', 'определённым', 'становится', 'другое', 'уравнение', 'шрёдингера', 'ключевая', 'формула', 'квантовой', 'теории', 'описывает', 'эволюцию', 'волновой', 'функции', 'явление', 'квантовой', 'запутанности', 'quantum', 'entanglement', 'эйнштейн', 'называл', 'жутким', 'действием', 'расстоянии', 'году', 'китайские', 'учёные', 'установили', 'новый', 'рекорд', 'удалось', 'запутать', 'фотонов', 'открывает', 'новые', 'горизонты', 'квантовых', 'компьютеров']\n",
            "['из', 'в', 'с', 'что', 'может', 'себя', 'и', 'как', 'и', 'как', 'и', 'чем', 'мы', 'тем', 'на', 'в', 'им', 'что', 'для']\n"
          ]
        }
      ],
      "source": [
        "filtered_tokens = [token for token in tokens if token not in russian_stopwords]\n",
        "stop_words = [token for token in tokens if token in russian_stopwords]\n",
        "print(filtered_tokens)\n",
        "print(stop_words)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sbV8P56O3-ZO"
      },
      "source": [
        "**Задание 5. Лемматизация и стемминг**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZ1A8VhK4HTk"
      },
      "source": [
        "Примените к токенам алгоритмы лемматизации и стемминга. Выведите 2 списка - 1. Лемматизированные токены 2. Стемматизированные токены"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrCmA4tt4WH6",
        "outputId": "0f549d0b-9673-45e4-f945-6d27a486abc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['квантов', 'механик', 'одн', 'сам', 'загадочн', 'област', 'современ', 'физик', 'мир', 'частиц', 'размер', 'м', 'действ', 'закон', 'противореча', 'наш', 'интуиц', 'эксперимент', 'двум', 'щел', 'double', 'slit', 'experiment', 'демонстрир', 'электрон', 'вест', 'частиц', 'волн', 'одновремен', 'принцип', 'неопределен', 'гейзенберг', 'утвержда', 'невозможн', 'одновремен', 'точн', 'измер', 'положен', 'импульс', 'частиц', 'точн', 'зна', 'одн', 'мен', 'определен', 'станов', 'друг', 'уравнен', 'шредингер', 'ключев', 'формул', 'квантов', 'теор', 'описыва', 'эволюц', 'волнов', 'функц', 'явлен', 'квантов', 'запутан', 'quantum', 'entanglement', 'эйнштейн', 'называ', 'жутк', 'действ', 'расстоян', 'год', 'китайск', 'учен', 'установ', 'нов', 'рекорд', 'уда', 'запута', 'фотон', 'открыва', 'нов', 'горизонт', 'квантов', 'компьютер']\n",
            "['квантовый', 'механика', 'один', 'самых', 'загадочный', 'область', 'современный', 'физика', 'мир', 'частица', 'размер', 'м', 'действовать', 'закон', 'противоречить', 'наш', 'интуиция', 'эксперимент', 'два', 'щель', 'double', 'slit', 'experiment', 'демонстрировать', 'электрон', 'вести', 'частица', 'волна', 'одновременно', 'принцип', 'неопределённость', 'гейзенберг', 'утверждать', 'невозможный', 'одновременно', 'точно', 'измерить', 'положение', 'импульс', 'частица', 'точнее', 'знать', 'одно', 'менее', 'определённым', 'становиться', 'другое', 'уравнение', 'шрёдингер', 'ключевой', 'формула', 'квантовый', 'теория', 'описывать', 'эволюция', 'волновой', 'функция', 'явление', 'квантовый', 'запутанность', 'quantum', 'entanglement', 'эйнштейн', 'называть', 'жуткий', 'действие', 'расстояние', 'год', 'китайский', 'учёный', 'установить', 'новый', 'рекорд', 'удаться', 'запутать', 'фотон', 'открывать', 'новый', 'горизонт', 'квантовый', 'компьютер']\n"
          ]
        }
      ],
      "source": [
        "# ваш код\n",
        "joined_tokens = ' '.join(filtered_tokens)\n",
        "doc = nlp_ru(joined_tokens)\n",
        "lemmas = [token.lemma_ for token in doc if token.is_alpha]\n",
        "\n",
        "stemmer = SnowballStemmer(\"russian\")\n",
        "words = re.findall(r'\\b\\w+\\b', joined_tokens)\n",
        "stems = [stemmer.stem(word) for word in words]\n",
        "print(stems)\n",
        "print(lemmas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_R2xPrh4bW6"
      },
      "source": [
        "**Задание 6. Напишите функцию для препроцессинга текста**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drJR_Rff4j_g"
      },
      "source": [
        "Объедините все шаги в одну функцию. Выведите результат с лемматизированным списком"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "RUE3jJp940iu",
        "outputId": "a273323c-0e97-44a4-84f6-440c1cc6da0d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Токены Очищенные токены Стоп-слова          Лемма         Стем\n",
              "0        квантовая        квантовая         из      квантовый      квантов\n",
              "1         механика         механика          в       механика      механик\n",
              "2             одна             одна          с           один          одн\n",
              "3               из            самых        что          самых          сам\n",
              "4            самых       загадочных      может     загадочный     загадочн\n",
              "5       загадочных         областей       себя        область       област\n",
              "6         областей      современной          и    современный     современ\n",
              "7      современной           физики        как         физика        физик\n",
              "8           физики             мире          и            мир          мир\n",
              "9                в           частиц        как        частица       частиц\n",
              "10            мире         размером          и         размер       размер\n",
              "11          частиц                м        чем              м            м\n",
              "12        размером        действуют         мы    действовать       действ\n",
              "13               м           законы        тем          закон        закон\n",
              "14       действуют   противоречащие         на  противоречить  противореча\n",
              "15          законы            нашей          в            наш          наш\n",
              "16  противоречащие         интуиции         им       интуиция       интуиц\n",
              "17           нашей      эксперимент        что    эксперимент  эксперимент\n",
              "18        интуиции            двумя        для            два         двум"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-899c28dc-9da2-4f4b-bc0a-7f5fe6175090\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Токены</th>\n",
              "      <th>Очищенные токены</th>\n",
              "      <th>Стоп-слова</th>\n",
              "      <th>Лемма</th>\n",
              "      <th>Стем</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>квантовая</td>\n",
              "      <td>квантовая</td>\n",
              "      <td>из</td>\n",
              "      <td>квантовый</td>\n",
              "      <td>квантов</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>механика</td>\n",
              "      <td>механика</td>\n",
              "      <td>в</td>\n",
              "      <td>механика</td>\n",
              "      <td>механик</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>одна</td>\n",
              "      <td>одна</td>\n",
              "      <td>с</td>\n",
              "      <td>один</td>\n",
              "      <td>одн</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>из</td>\n",
              "      <td>самых</td>\n",
              "      <td>что</td>\n",
              "      <td>самых</td>\n",
              "      <td>сам</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>самых</td>\n",
              "      <td>загадочных</td>\n",
              "      <td>может</td>\n",
              "      <td>загадочный</td>\n",
              "      <td>загадочн</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>загадочных</td>\n",
              "      <td>областей</td>\n",
              "      <td>себя</td>\n",
              "      <td>область</td>\n",
              "      <td>област</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>областей</td>\n",
              "      <td>современной</td>\n",
              "      <td>и</td>\n",
              "      <td>современный</td>\n",
              "      <td>современ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>современной</td>\n",
              "      <td>физики</td>\n",
              "      <td>как</td>\n",
              "      <td>физика</td>\n",
              "      <td>физик</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>физики</td>\n",
              "      <td>мире</td>\n",
              "      <td>и</td>\n",
              "      <td>мир</td>\n",
              "      <td>мир</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>в</td>\n",
              "      <td>частиц</td>\n",
              "      <td>как</td>\n",
              "      <td>частица</td>\n",
              "      <td>частиц</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>мире</td>\n",
              "      <td>размером</td>\n",
              "      <td>и</td>\n",
              "      <td>размер</td>\n",
              "      <td>размер</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>частиц</td>\n",
              "      <td>м</td>\n",
              "      <td>чем</td>\n",
              "      <td>м</td>\n",
              "      <td>м</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>размером</td>\n",
              "      <td>действуют</td>\n",
              "      <td>мы</td>\n",
              "      <td>действовать</td>\n",
              "      <td>действ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>м</td>\n",
              "      <td>законы</td>\n",
              "      <td>тем</td>\n",
              "      <td>закон</td>\n",
              "      <td>закон</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>действуют</td>\n",
              "      <td>противоречащие</td>\n",
              "      <td>на</td>\n",
              "      <td>противоречить</td>\n",
              "      <td>противореча</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>законы</td>\n",
              "      <td>нашей</td>\n",
              "      <td>в</td>\n",
              "      <td>наш</td>\n",
              "      <td>наш</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>противоречащие</td>\n",
              "      <td>интуиции</td>\n",
              "      <td>им</td>\n",
              "      <td>интуиция</td>\n",
              "      <td>интуиц</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>нашей</td>\n",
              "      <td>эксперимент</td>\n",
              "      <td>что</td>\n",
              "      <td>эксперимент</td>\n",
              "      <td>эксперимент</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>интуиции</td>\n",
              "      <td>двумя</td>\n",
              "      <td>для</td>\n",
              "      <td>два</td>\n",
              "      <td>двум</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-899c28dc-9da2-4f4b-bc0a-7f5fe6175090')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-899c28dc-9da2-4f4b-bc0a-7f5fe6175090 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-899c28dc-9da2-4f4b-bc0a-7f5fe6175090');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "result_df",
              "summary": "{\n  \"name\": \"result_df\",\n  \"rows\": 19,\n  \"fields\": [\n    {\n      \"column\": \"\\u0422\\u043e\\u043a\\u0435\\u043d\\u044b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"\\u043a\\u0432\\u0430\\u043d\\u0442\\u043e\\u0432\\u0430\\u044f\",\n          \"\\u0437\\u0430\\u0433\\u0430\\u0434\\u043e\\u0447\\u043d\\u044b\\u0445\",\n          \"\\u0447\\u0430\\u0441\\u0442\\u0438\\u0446\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041e\\u0447\\u0438\\u0449\\u0435\\u043d\\u043d\\u044b\\u0435 \\u0442\\u043e\\u043a\\u0435\\u043d\\u044b\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"\\u043a\\u0432\\u0430\\u043d\\u0442\\u043e\\u0432\\u0430\\u044f\",\n          \"\\u043e\\u0431\\u043b\\u0430\\u0441\\u0442\\u0435\\u0439\",\n          \"\\u043c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0421\\u0442\\u043e\\u043f-\\u0441\\u043b\\u043e\\u0432\\u0430\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14,\n        \"samples\": [\n          \"\\u043c\\u044b\",\n          \"\\u043d\\u0430\",\n          \"\\u0438\\u0437\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u041b\\u0435\\u043c\\u043c\\u0430\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"\\u043a\\u0432\\u0430\\u043d\\u0442\\u043e\\u0432\\u044b\\u0439\",\n          \"\\u043e\\u0431\\u043b\\u0430\\u0441\\u0442\\u044c\",\n          \"\\u043c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"\\u0421\\u0442\\u0435\\u043c\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"\\u043a\\u0432\\u0430\\u043d\\u0442\\u043e\\u0432\",\n          \"\\u043e\\u0431\\u043b\\u0430\\u0441\\u0442\",\n          \"\\u043c\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# ваш код\n",
        "def preprocessing(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "    text = re.sub(r'\\n', ' ', text)\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = text.strip()\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)\n",
        "\n",
        "    tokens = text.split()\n",
        "\n",
        "    filtered_tokens = [token for token in tokens if token not in russian_stopwords]\n",
        "    stop_words = [token for token in tokens if token in russian_stopwords]\n",
        "\n",
        "\n",
        "    joined_tokens = ' '.join(filtered_tokens)\n",
        "    doc = nlp_ru(joined_tokens)\n",
        "    lemmas = [token.lemma_ for token in doc if token.is_alpha]\n",
        "\n",
        "    stemmer = SnowballStemmer(\"russian\")\n",
        "    words = re.findall(r'\\b\\w+\\b', joined_tokens)\n",
        "    stems = [stemmer.stem(word) for word in words]\n",
        "    return tokens, filtered_tokens, stop_words, lemmas, stems\n",
        "\n",
        "tokens, filtered_tokens, stop_words, lemmas, stems = preprocessing(original_text)\n",
        "\n",
        "result = []\n",
        "for t, ft, sw, lem, stem in zip(tokens, filtered_tokens, stop_words, lemmas, stems):\n",
        "    result.append({\n",
        "        \"Токены\": t,\n",
        "        \"Очищенные токены\": ft,\n",
        "        \"Стоп-слова\": sw,\n",
        "        \"Лемма\": lem,\n",
        "        \"Стем\": stem\n",
        "    })\n",
        "\n",
        "result_df = pd.DataFrame(result)\n",
        "result_df\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}