{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["В этом ноутбуке вы узнаете:\n","\n","1.   Как использовать встроенные методы Python для работы со строками\n","2.   Как выполнять базовую нормализацию текста\n","3. Как токенизировать текст с помощью простых методов\n","4. Как применять эти навыки на практике\n"],"metadata":{"id":"xaCyWYJ6uGfk"}},{"cell_type":"markdown","source":["**1. Основные понятия и функции**"],"metadata":{"id":"T4-yFhGcy934"}},{"cell_type":"markdown","source":["В Python текст представлен в виде строк (тип данных str). Строки можно создавать, используя одинарные или двойные кавычки."],"metadata":{"id":"mMYBk9PluRfs"}},{"cell_type":"code","source":["# Создание строк\n","text1 = 'Это текст в \"одинарных\" кавычках'\n","text2 = \"Это текст в 'двойных' кавычках\"\n","text3 = '''Это текст в \"тройных\" кавычках'''\n","text4 = '''Это\n","текст\n","в 'тройных'\n","кавычках'''\n","\n","# Вывод строк\n","print(text1)\n","print(text2)\n","print(text3)\n","print(text4)"],"metadata":{"id":"tXalOImZuMdk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759468756587,"user_tz":-240,"elapsed":24,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"6d786d0a-2a05-4942-897c-8b2e27826f5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Это текст в \"одинарных\" кавычках\n","Это текст в 'двойных' кавычках\n","Это текст в \"тройных\" кавычках\n","Это\n","текст\n","в 'тройных'\n","кавычках\n"]}]},{"cell_type":"markdown","source":["1.1. Индексация и срезы строк.\n","Строки в Python — это последовательности символов, к которым можно обращаться по индексу. Индексация начинается с 0."],"metadata":{"id":"4dVUdNKvuYvU"}},{"cell_type":"code","source":["# Строка для примеров\n","sample_text = \"Компьютерная лингвистика\"\n","\n","# Получение отдельного символа\n","print(\"Первый символ:\", sample_text[0])\n","print(\"Пятый символ:\", sample_text[4])\n","\n","# Срезы строк\n","print(\"Первые 12 символов:\", sample_text[:12])  # от начала до 12-го символа (не включая)\n","print(\"С 13-го символа до конца:\", sample_text[13:])  # с 13-го символа до конца\n","print(\"С 5-го по 10-й символ:\", sample_text[5:11])  # с 5-го по 10-й символ (11-й не включается)"],"metadata":{"id":"8RlZDm97uVrC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759468808802,"user_tz":-240,"elapsed":59,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"cbb573d8-02cc-4c46-c375-abe05be9859e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Первый символ: К\n","Пятый символ: ь\n","Первые 12 символов: Компьютерная\n","С 13-го символа до конца: лингвистика\n","С 5-го по 10-й символ: ютерна\n"]}]},{"cell_type":"markdown","source":["1.2. Основные методы строк\n","Python предоставляет множество встроенных методов для работы со строками. Рассмотрим наиболее полезные для обработки текста:"],"metadata":{"id":"-oi1N22TvbQx"}},{"cell_type":"code","source":["# Строка для примеров\n","text = \"   Пример текста для анализа.   \"\n","\n","# Удаление пробелов в начале и конце строки\n","print(\"После strip():\", text.strip())\n","\n","# Перевод в нижний регистр\n","print(\"После lower():\", text.lower())\n","\n","# Перевод в верхний регистр\n","print(\"После upper():\", text.upper())\n","\n","# Проверка, начинается ли строка с определенной подстроки\n","print(\"Начинается с 'Пример'?\", text.strip().startswith(\"Пример\"))\n","\n","# Проверка, заканчивается ли строка определенной подстрокой\n","print(\"Заканчивается на '.'?\", text.strip().endswith(\".\"))\n","\n","# Замена подстроки\n","print(\"После replace():\", text.replace(\"анализа\", \"обработки\"))\n","\n","# Подсчет вхождений подстроки\n","print(\"Количество пробелов:\", text.count(\" \"))"],"metadata":{"id":"vkcKQqqgvcpk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759468837978,"user_tz":-240,"elapsed":20,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"df24bb92-2012-425c-c6ee-70b726051181"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["После strip(): Пример текста для анализа.\n","После lower():    пример текста для анализа.   \n","После upper():    ПРИМЕР ТЕКСТА ДЛЯ АНАЛИЗА.   \n","Начинается с 'Пример'? True\n","Заканчивается на '.'? True\n","После replace():    Пример текста для обработки.   \n","Количество пробелов: 9\n"]}]},{"cell_type":"markdown","source":["1.3. Конкатенация строк и форматирование.\n","Существует несколько способов объединения строк в Python:"],"metadata":{"id":"-oEf7vLCvvzL"}},{"cell_type":"code","source":["# Простая конкатенация с помощью оператора +\n","first_name = \"Иван\"\n","last_name = \"Петров\"\n","full_name = first_name + \" \" + last_name\n","print(\"Полное имя:\", full_name)\n","\n","# Форматирование строк с помощью метода format()\n","age = 25\n","message = \"Меня зовут {}, мне {} лет.\".format(full_name, age)\n","print(message)\n","\n","# f-строки (начиная с Python 3.6)\n","message_f = f\"Меня зовут {full_name}, мне {age} лет.\"\n","print(message_f)\n","\n","# Использование %\n","message_old = \"Меня зовут %s, мне %d лет.\" % (full_name, age)\n","print(message_old)"],"metadata":{"id":"CS50TkzKvwfk","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759468899670,"user_tz":-240,"elapsed":10,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"75e78c9f-3521-4da6-eb00-845f9a640d0b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Полное имя: Иван Петров\n","Меня зовут Иван Петров, мне 25 лет.\n","Меня зовут Иван Петров, мне 25 лет.\n","Меня зовут Иван Петров, мне 25 лет.\n"]}]},{"cell_type":"markdown","source":["**2. Базовая нормализация текста**"],"metadata":{"id":"e0K6mt6Vv6gV"}},{"cell_type":"markdown","source":["Нормализация текста — это процесс преобразования текста к стандартному виду для облегчения его дальнейшей обработки. Рассмотрим базовые операции нормализации."],"metadata":{"id":"hL2BXNo8wEVY"}},{"cell_type":"markdown","source":["2.1. Приведение к нижнему регистру помогает унифицировать текст. Обычно используется нижний регистр."],"metadata":{"id":"J5Gk1AnRwHK0"}},{"cell_type":"code","source":["# Пример текста с разным регистром\n","mixed_case_text = \"КомпьЮтерная ЛИНГвистика изучает Методы Автоматической Обработки Текста.\"\n","\n","# Приведение к нижнему регистру\n","normalized_text = mixed_case_text.lower()\n","print(\"Исходный текст:\", mixed_case_text)\n","print(\"Нормализованный текст:\", normalized_text)\n","\n","# Пример на английском\n","english_text = \"Natural Language Processing (NLP) is a FIELD of AI.\"\n","print(\"Английский текст после нормализации:\", english_text.lower())"],"metadata":{"id":"vNNMpCqOv2Dz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759468955547,"user_tz":-240,"elapsed":19,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"a3a2679a-166d-4400-a12b-067840c0604a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Исходный текст: КомпьЮтерная ЛИНГвистика изучает Методы Автоматической Обработки Текста.\n","Нормализованный текст: компьютерная лингвистика изучает методы автоматической обработки текста.\n","Английский текст после нормализации: natural language processing (nlp) is a field of ai.\n"]}]},{"cell_type":"markdown","source":["2.2. Удаление лишних пробелов. Часто тексты содержат лишние пробелы, которые нужно удалить.\n","\n","\n"],"metadata":{"id":"Vlwzl4-bw7u9"}},{"cell_type":"code","source":["# Текст с лишними пробелами\n","text_with_spaces = \"   В  этом   тексте  есть  лишние    пробелы.   \"\n","\n","# Удаление пробелов в начале и конце\n","trimmed_text = text_with_spaces.strip()\n","print(\"После strip():\", trimmed_text)\n","\n","words = trimmed_text.split()  # Разбиваем текст на слова\n","normalized_manually = ' '.join(words)  # Объединяем слова с одним пробелом\n","print(\"Нормализация:\", normalized_manually)\n","\n","# Пример на английском\n","english_spaces = \"  This   text   has   extra   spaces. \"\n","english_normalized = ' '.join(english_spaces.strip().split())\n","print(\"Английский текст после нормализации пробелов:\", english_normalized)"],"metadata":{"id":"AioDUYPrw-Hl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759468984371,"user_tz":-240,"elapsed":57,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"7e7e92dd-5927-4a2c-df73-388b44b53a97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["После strip(): В  этом   тексте  есть  лишние    пробелы.\n","Нормализация: В этом тексте есть лишние пробелы.\n","Английский текст после нормализации пробелов: This text has extra spaces.\n"]}]},{"cell_type":"markdown","source":["2.3. Удаление пунктуации. Для многих задач обработки текста необходимо удалить знаки пунктуации."],"metadata":{"id":"M7bFiY8syfRf"}},{"cell_type":"code","source":["# Текст с пунктуацией\n","text_with_punctuation = \"Привет, мир! Как дела? Это - пример текста; с разными знаками пунктуации.\"\n","\n","# Определение знаков пунктуации для удаления\n","import string\n","punctuation = string.punctuation  # !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n","print(\"Знаки пунктуации:\", punctuation)\n","\n","# Удаление пунктуации (метод 1)\n","no_punctuation = ''.join(char for char in text_with_punctuation if char not in punctuation)\n","print(\"Текст без пунктуации (метод 1):\", no_punctuation)\n","\n","# Удаление пунктуации (метод 2)\n","translator = str.maketrans('', '', punctuation)\n","no_punctuation2 = text_with_punctuation.translate(translator)\n","print(\"Текст без пунктуации (метод 2):\", no_punctuation2)\n","\n","# Пример на английском\n","english_punctuation = \"Hello, world! How are you? This is a sample text; with various punctuation marks.\"\n","english_no_punctuation = english_punctuation.translate(translator)\n","print(\"Английский текст без пунктуации:\", english_no_punctuation)"],"metadata":{"id":"g7M5Bna1yjB1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["2.4. Комплексная нормализация текста. Объединим все изученные методы для комплексной нормализации текста."],"metadata":{"id":"cCzDj3GayrSf"}},{"cell_type":"code","source":["def normalize_text(text):\n","    \"\"\"\n","    Функция для комплексной нормализации текста:\n","    1. Приведение к нижнему регистру\n","    2. Удаление лишних пробелов\n","    3. Удаление пунктуации\n","    \"\"\"\n","    # Шаг 1: Приведение к нижнему регистру\n","    text = text.lower()\n","\n","    # Шаг 2: Удаление пунктуации\n","    translator = str.maketrans('', '', string.punctuation)\n","    text = text.translate(translator)\n","\n","    # Шаг 3: Удаление лишних пробелов\n","    text = ' '.join(text.split())\n","\n","    return text\n","\n","# Проверка функции на русском тексте\n","russian_text = \"   Компьютерная    ЛИНГВИСТИКА - это ОБЛАСТЬ науки, изучающая   методы автоматической    обработки текста!   \"\n","normalized_russian = normalize_text(russian_text)\n","print(\"Исходный русский текст:\", russian_text)\n","print(\"Нормализованный русский текст:\", normalized_russian)\n","\n","# Проверка функции на английском тексте\n","english_text = \"   Natural    LANGUAGE Processing (NLP) - is a FIELD of AI, focusing   on text analysis!   \"\n","normalized_english = normalize_text(english_text)\n","print(\"Исходный английский текст:\", english_text)\n","print(\"Нормализованный английский текст:\", normalized_english)"],"metadata":{"id":"-EQfaUxNyuOm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**3. Простая токенизация текста**"],"metadata":{"id":"H2IvHG_yy1uJ"}},{"cell_type":"markdown","source":["Токенизация — это процесс разделения текста на отдельные токены (обычно слова или предложения). Рассмотрим простые методы токенизации с использованием встроенных возможностей Python."],"metadata":{"id":"ISndfr9tzMRC"}},{"cell_type":"markdown","source":["3.1. Токенизация по пробелам. Самый простой способ токенизации — разделение текста по пробелам с помощью метода .split()."],"metadata":{"id":"sjvNUNImzP5i"}},{"cell_type":"code","source":["# Пример текста\n","text = \"Компьютерная лингвистика изучает методы обработки текста\"\n","\n","# Токенизация по пробелам\n","tokens = text.split()\n","print(\"Токены:\", tokens)\n","print(\"Количество токенов:\", len(tokens))\n","\n","# Токенизация английского текста\n","english_text = \"Natural language processing studies methods of text analysis\"\n","english_tokens = english_text.split()\n","print(\"Английские токены:\", english_tokens)\n","print(\"Количество английских токенов:\", len(english_tokens))"],"metadata":{"id":"pRMRYdZfzTk2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759469042580,"user_tz":-240,"elapsed":16,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"7e562ff3-dc89-4dc1-aec4-bfc2bb9dbe79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Токены: ['Компьютерная', 'лингвистика', 'изучает', 'методы', 'обработки', 'текста']\n","Количество токенов: 6\n","Английские токены: ['Natural', 'language', 'processing', 'studies', 'methods', 'of', 'text', 'analysis']\n","Количество английских токенов: 8\n"]}]},{"cell_type":"markdown","source":["3.2. Токенизация с учетом пунктуации. Токенизация по пробелам не учитывает пунктуацию. Для более точной токенизации можно сначала отделить пунктуацию от слов."],"metadata":{"id":"Ey-4jl42zahC"}},{"cell_type":"code","source":["def simple_tokenize(text):\n","    \"\"\"\n","    Простая токенизация с учетом пунктуации:\n","    1. Добавляем пробелы вокруг знаков пунктуации\n","    2. Разделяем по пробелам\n","    3. Удаляем пустые токены\n","    \"\"\"\n","    # Добавляем пробелы вокруг знаков пунктуации\n","    for punct in string.punctuation:\n","        text = text.replace(punct, f' {punct} ')\n","\n","    # Разделяем по пробелам и удаляем пустые токены\n","    tokens = [token for token in text.split() if token]\n","\n","    return tokens\n","\n","# Проверка на русском тексте\n","russian_text = \"Привет, мир! Как дела? Это - пример текста; с разными знаками пунктуации.\"\n","russian_tokens = simple_tokenize(russian_text)\n","print(\"Русский текст:\", russian_text)\n","print(\"Токены русского текста:\", russian_tokens)\n","print(\"Количество токенов:\", len(russian_tokens))\n","\n","# Проверка на английском тексте\n","english_text = \"Hello, world! How are you? This is a sample text; with various punctuation marks.\"\n","english_tokens = simple_tokenize(english_text)\n","print(\"Английский текст:\", english_text)\n","print(\"Токены английского текста:\", english_tokens)\n","print(\"Количество токенов:\", len(english_tokens))"],"metadata":{"id":"8rYkdzlnzdkp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759286569166,"user_tz":-240,"elapsed":82,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"e5d2fa66-1157-4c3e-f22b-2424be91512c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Русский текст: Привет, мир! Как дела? Это - пример текста; с разными знаками пунктуации.\n","Токены русского текста: ['Привет', ',', 'мир', '!', 'Как', 'дела', '?', 'Это', '-', 'пример', 'текста', ';', 'с', 'разными', 'знаками', 'пунктуации', '.']\n","Количество токенов: 17\n","Английский текст: Hello, world! How are you? This is a sample text; with various punctuation marks.\n","Токены английского текста: ['Hello', ',', 'world', '!', 'How', 'are', 'you', '?', 'This', 'is', 'a', 'sample', 'text', ';', 'with', 'various', 'punctuation', 'marks', '.']\n","Количество токенов: 19\n"]}]},{"cell_type":"markdown","source":["3.3. Токенизация предложений. Простой способ — разделение по знакам конца предложения."],"metadata":{"id":"qfbRKk1S0wq_"}},{"cell_type":"code","source":["def simple_sentence_tokenize(text):\n","    \"\"\"\n","    Простая токенизация на предложения:\n","    1. Заменяем знаки конца предложения на специальный маркер\n","    2. Разделяем текст по маркеру\n","    3. Очищаем полученные предложения\n","    \"\"\"\n","    # Заменяем знаки конца предложения\n","    for end_mark in ['.', '!', '?']:\n","        text = text.replace(end_mark, f'{end_mark}SENTENCE_END')\n","\n","    # Разделяем по маркеру\n","    sentences = text.split('SENTENCE_END')\n","\n","    # Очищаем предложения и удаляем пустые\n","    cleaned_sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n","\n","    return cleaned_sentences\n","\n","# Проверка на русском тексте\n","russian_text = \"Привет, мир! Как дела? Это пример текста. Он состоит из нескольких предложений.\"\n","russian_sentences = simple_sentence_tokenize(russian_text)\n","print(\"Русский текст:\", russian_text)\n","print(\"Предложения русского текста:\")\n","for i, sentence in enumerate(russian_sentences, 1):\n","    print(f\"{i}. {sentence}\")\n","\n","# Проверка на английском тексте\n","english_text = \"Hello, world! How are you? This is a sample text. It consists of several sentences.\"\n","english_sentences = simple_sentence_tokenize(english_text)\n","print(\"\\nАнглийский текст:\", english_text)\n","print(\"Предложения английского текста:\")\n","for i, sentence in enumerate(english_sentences, 1):\n","    print(f\"{i}. {sentence}\")"],"metadata":{"id":"bw3dAKeG0-fA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759469285098,"user_tz":-240,"elapsed":29,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"dfc3fde6-d43e-4054-b62a-ec0f33179790"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Русский текст: Привет, мир! Как дела? Это пример текста. Он состоит из нескольких предложений.\n","Предложения русского текста:\n","1. Привет, мир!\n","2. Как дела?\n","3. Это пример текста.\n","4. Он состоит из нескольких предложений.\n","\n","Английский текст: Hello, world! How are you? This is a sample text. It consists of several sentences.\n","Предложения английского текста:\n","1. Hello, world!\n","2. How are you?\n","3. This is a sample text.\n","4. It consists of several sentences.\n"]}]},{"cell_type":"markdown","source":["3.4. Объединение токенов обратно в текст. Метод .join() позволяет объединить токены обратно в текст, указав разделитель."],"metadata":{"id":"_a-rRcLp1NnW"}},{"cell_type":"code","source":["# Пример токенов\n","tokens = [\"Компьютерная\", \"лингвистика\", \"изучает\", \"методы\", \"обработки\", \"текста\"]\n","\n","# Объединение токенов с пробелом\n","text = ' '.join(tokens)\n","print(\"Объединенный текст:\", text)\n","\n","# Объединение с другими разделителями\n","comma_separated = ', '.join(tokens)\n","print(\"Токены через запятую:\", comma_separated)\n","\n","# Объединение английских токенов\n","english_tokens = [\"Natural\", \"language\", \"processing\", \"studies\", \"methods\", \"of\", \"text\", \"analysis\"]\n","english_text = ' '.join(english_tokens)\n","print(\"Объединенный английский текст:\", english_text)"],"metadata":{"id":"jCOkR50y1PYv","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759286824858,"user_tz":-240,"elapsed":18,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"c29b5d94-f9a2-41a3-d971-cacff91066d6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Объединенный текст: Компьютерная лингвистика изучает методы обработки текста\n","Токены через запятую: Компьютерная, лингвистика, изучает, методы, обработки, текста\n","Объединенный английский текст: Natural language processing studies methods of text analysis\n"]}]},{"cell_type":"markdown","source":["**4. Практические упражнения**"],"metadata":{"id":"zTAF-Lj21evo"}},{"cell_type":"markdown","source":["Упражнение 1: Нормализация текста. Напишите функцию, которая будет нормализовать текст следующим образом:\n","\n","1. Привести к нижнему регистру\n","2. Удалить все цифры\n","3. Заменить все символы пунктуации на пробелы\n","4. Удалить лишние пробелы\n","\n"],"metadata":{"id":"2ffDLEVL1oiZ"}},{"cell_type":"code","source":["#убираем цифорки\n","import string\n","def normalize_text(sample_text):\n","    punctuation = string.punctuation\n","    numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"];\n","    # ваш код\n","\n","    #приводим к нижнему регистру\n","    sample_text_lower = sample_text.lower();\n","\n","    #удаляем цифры\n","    sample_text_no_numbers = ''.join(char for char in sample_text_lower if char not in numbers)\n","\n","    #заменяем все символы пунктуации на пробелы\n","    translator = str.maketrans('', '', punctuation)\n","    output_text = sample_text_no_numbers.translate(translator)\n","\n","    #Удаление лишних пробелов\n","    output_text = ' '.join(output_text.split())\n","    print(f'Нормализированный текст: {output_text}');\n","sample_text = \"Пример текста123, с РАЗНЫМИ символами! И 456 цифрами?!\"\n","normalize_text(sample_text)\n"],"metadata":{"id":"rU4ZTUrd1jFX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760179839102,"user_tz":-240,"elapsed":12,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"dd508290-86d2-4d9a-d322-7f9b1c314cf3"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Нормализированный текст: пример текста с разными символами и цифрами\n"]}]},{"cell_type":"markdown","source":["Упражнение 2: Подсчет частотности слов. Напишите функцию, которая будет принимать текст, нормализовать его, токенизировать и возвращать словарь с частотностью каждого слова."],"metadata":{"id":"waC9ZHWB2Kph"}},{"cell_type":"code","source":["def get_frequency(text):\n","  #НОРМАЛИЗАЦИЯ ТЕКСТОВ\n","  #убираем цифорки\n","  import string\n","  punctuation = string.punctuation\n","  numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"];\n","  #приводим к нижнему регистру\n","  text = text.lower();\n","  #удаляем цифры\n","  text_no_numbers = ''.join(char for char in text if char not in numbers);\n","  #заменяем все символы пунктуации на пробелы\n","  translator = str.maketrans('', '', punctuation)\n","  normal_text = text_no_numbers.translate(translator)\n","  #Удаление лишних пробелов\n","  normal_text = ' '.join(normal_text.split())\n","  #ТОКЕНИЗАЦИЯ ТЕКСТОВ\n","  #Токенизация по пробелам\n","  tokens = normal_text.split()\n","  #Кладем в словарь частотность каждого слова\n","  dict = {}\n","  for i in tokens:\n","    if i in dict.keys():\n","      dict[i]+=1;\n","    else:\n","      dict[i] = 1;\n","  print(dict)\n","\n","sample_text = \"Компьютерная лингвистика изучает методы обработки текста. Компьютерная лингвистика является областью искусственного интеллекта.\"\n","english_text = \"Natural language processing is a field of artificial intelligence. Natural language processing focuses on the interaction between computers and humans.\"\n","# ваш код\n","get_frequency(sample_text)\n","get_frequency(english_text)\n"],"metadata":{"id":"HlWO9Bpn2SQo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759474623994,"user_tz":-240,"elapsed":69,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"9dd6324b-8366-47fd-9e31-01a38bb17848"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'компьютерная': 2, 'лингвистика': 2, 'изучает': 1, 'методы': 1, 'обработки': 1, 'текста': 1, 'является': 1, 'областью': 1, 'искусственного': 1, 'интеллекта': 1}\n","{'natural': 2, 'language': 2, 'processing': 2, 'is': 1, 'a': 1, 'field': 1, 'of': 1, 'artificial': 1, 'intelligence': 1, 'focuses': 1, 'on': 1, 'the': 1, 'interaction': 1, 'between': 1, 'computers': 1, 'and': 1, 'humans': 1}\n"]}]},{"cell_type":"markdown","source":["Упражнение 3: Поиск самых длинных и коротких слов. Напишите функцию, которая находит самые длинные и самые короткие слова в тексте."],"metadata":{"id":"RPTWlfsD2ehu"}},{"cell_type":"code","source":["def get_longest_word(text):\n","  #НОРМАЛИЗАЦИЯ ТЕКСТОВ\n","  #убираем цифорки\n","  import string\n","  punctuation = string.punctuation\n","  numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"];\n","  #приводим к нижнему регистру\n","  text = text.lower();\n","  #удаляем цифры\n","  text_no_numbers = ''.join(char for char in text if char not in numbers);\n","  #заменяем все символы пунктуации на пробелы\n","  translator = str.maketrans('', '', punctuation)\n","  normal_text = text_no_numbers.translate(translator)\n","  #Удаление лишних пробелов\n","  normal_text = ' '.join(normal_text.split())\n","  #ТОКЕНИЗАЦИЯ ТЕКСТОВ\n","  #Токенизация по пробелам\n","  tokens = normal_text.split()\n","  #print(tokens)\n","\n","  max_length = len(tokens[0])\n","  min_length = len(tokens[0])\n","  long_words = []\n","  short_words = []\n","  for i in tokens:\n","    #ищем самое длинное слово\n","    if len(i) == max_length and i not in long_words: #добавляем слово в список длинных слов, только если оно еще не добавлено\n","      long_words.append(i)\n","\n","    elif len(i) > max_length:\n","      long_words.clear()\n","      long_words.append(i)\n","      max_length = len(i)\n","    #ищем самое короткое слово\n","    if len(i) == min_length and i not in short_words: #добавляем слово в список коротких слов, только если оно еще не добавлено\n","      short_words.append(i)\n","    elif len(i) < min_length:\n","      short_words.clear()\n","      short_words.append(i)\n","      min_length = len(i)\n","  #выводим результат\n","  print(f\"\\tСамые длинные слова: {long_words}\") if len(long_words) > 1 else print(f\"\\tСамое длинное слово: {long_words}\")\n","  print(f\"\\tСамые короткие слова: {short_words}\") if len(short_words) > 1 else print(f\"\\tСамое короткое слово: {short_words}\")\n","\n","sample_text = \"Компьютерная лингвистика является междисциплинарной областью междисциплинарной науки, которая изучает математические и компьютерные модели естественного языка, а также его применение в системах искусственного интеллекта.\"\n","english_text = \"Computational linguistics is an interdisciplinary field of science that studies mathematical and computational models of natural language and its application in artificial intelligence systems.\"\n","# ваш код\n","print(\"В тексте на русском языке:\")\n","get_longest_word(sample_text)\n","print(\"В тексте на английском языке:\")\n","get_longest_word(english_text)"],"metadata":{"id":"hizov4xW2YhX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759473667365,"user_tz":-240,"elapsed":36,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"9f8aa4eb-6607-49ab-c097-d15cef8b0d6d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["В тексте на русском языке:\n","\tСамое длинное слово: ['междисциплинарной']\n","\tСамые короткие слова: ['и', 'а', 'в']\n","В тексте на английском языке:\n","\tСамое длинное слово: ['interdisciplinary']\n","\tСамые короткие слова: ['is', 'an', 'of', 'in']\n"]}]},{"cell_type":"markdown","source":["Упражнение 4: Поиск и подсчет определенных паттернов. Напишите функцию, которая находит и подсчитывает слова, начинающиеся с определенной буквы или содержащие определенную последовательность букв."],"metadata":{"id":"wtQ6vmk922D6"}},{"cell_type":"code","source":["import string\n","def find_k_words(sample_text):\n","    kwords =[]\n","    # Поиск слов, начинающихся с 'к'\n","    #НОРМАЛИЗАЦИЯ ТЕКСТОВ\n","    #убираем цифорки\n","    punctuation = string.punctuation\n","    numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"];\n","    #приводим к нижнему регистру\n","    text = sample_text.lower();\n","    #удаляем цифры\n","    text_no_numbers = ''.join(char for char in text if char not in numbers);\n","    #заменяем все символы пунктуации на пробелы\n","    translator = str.maketrans('', '', punctuation)\n","    normal_text = text_no_numbers.translate(translator)\n","    #Удаление лишних пробелов\n","    normal_text = ' '.join(normal_text.split())\n","    #ТОКЕНИЗАЦИЯ ТЕКСТОВ\n","    #Токенизация по пробелам\n","    tokens = normal_text.split()\n","    quantity = 0\n","    for i in tokens:\n","      if i[0][0] =='к':\n","        quantity += 1\n","        new_i = re.sub(r'к', 'К', i)\n","        kwords.append(new_i)\n","    print(f\"Количество слов, начинающихся на букву «к»: {quantity} ({kwords})\")\n","\n","sample_text = \"Компьютерная лингвистика изучает методы обработки текста. Математические модели и компьютерные алгоритмы используются для анализа естественных языков.\"\n","find_k_words(sample_text)"],"metadata":{"id":"Pv0AYXVp23vc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760180454345,"user_tz":-240,"elapsed":27,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"90dbcc1f-c1e8-4582-ae0e-b19589496dd4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество слов, начинающихся на букву «к»: 2 (['Компьютерная', 'Компьютерные'])\n"]}]},{"cell_type":"code","source":["import re\n","def find_ing_words(english_text):\n","  ingwords = []\n","  # Поиск слов, содержащих 'ing'\n","  # ваш код\n","  #НОРМАЛИЗАЦИЯ ТЕКСТОВ\n","  #убираем цифорки\n","  import string\n","  punctuation = string.punctuation\n","  numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"];\n","  #приводим к нижнему регистру\n","  text = english_text.lower();\n","  #удаляем цифры\n","  text_no_numbers = ''.join(char for char in text if char not in numbers);\n","  #заменяем все символы пунктуации на пробелы\n","  translator = str.maketrans('', '', punctuation)\n","  normal_text = text_no_numbers.translate(translator)\n","  #Удаление лишних пробелов\n","  normal_text = ' '.join(normal_text.split())\n","  #ТОКЕНИЗАЦИЯ ТЕКСТОВ\n","  #Токенизация по пробелам\n","  tokens = normal_text.split()\n","  quantity = 0\n","  for i in tokens:\n","    if 'ing' in i:\n","      quantity += 1\n","      new_i = re.sub(r'ing', 'ING', i)\n","      ingwords.append(new_i)\n","  print(f\"Количество слов, содержащих «ing»: {quantity} ({ingwords})\")\n","\n","english_text = \"Computational linguistics studies methods of text processing. Mathematical models and computer algorithms are used to analyze natural languages.\"\n","find_ing_words(english_text)"],"metadata":{"id":"1i4Yjoum26nz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760180421141,"user_tz":-240,"elapsed":26,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"3efd2078-b09a-4ff4-8d29-051aaf6821af"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Количество слов, содержащих «ing»: 2 (['lINGuistics', 'processING'])\n"]}]},{"cell_type":"markdown","source":["Упражнение 5: Анализ предложений в тексте. Напишите функцию, которая анализирует текст на уровне предложений, подсчитывая:\n","\n","1. Количество предложений\n","2. Среднюю длину предложения (в словах)\n","3. Самое длинное и самое короткое предложение\n"],"metadata":{"id":"anDhdjLG3M1A"}},{"cell_type":"code","source":["# ваш код\n","def simple_sentence_tokenize(text):\n","    \"\"\"\n","    Простая токенизация на предложения:\n","    1. Заменяем знаки конца предложения на специальный маркер\n","    2. Разделяем текст по маркеру\n","    3. Очищаем полученные предложения\n","    \"\"\"\n","    # Заменяем знаки конца предложения\n","    for end_mark in ['.', '!', '?']:\n","        text = text.replace(end_mark, f'{end_mark}SENTENCE_END')\n","\n","    # Разделяем по маркеру\n","    sentences = text.split('SENTENCE_END')\n","\n","    # Очищаем предложения и удаляем пустые\n","    cleaned_sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n","\n","    return cleaned_sentences\n","def analyze_sentences(sample_text):\n","  #Считаем количество предложений\n","  sentences = simple_sentence_tokenize(sample_text)\n","\n","  sum = 0\n","  max_length = len(sentences[0])\n","  min_length = len(sentences[0])\n","  long_sentence = sentences[0]\n","  short_sentence = sentences[0]\n","\n","  for i in sentences:\n","    #ищем самое длинное предложение\n","    if len(i) >= max_length:\n","      long_sentence = i\n","      max_length = len(i)\n","    #ищем самое короткое предложение\n","    if len(i) <= min_length:\n","      short_sentence = i\n","      min_length = len(i)\n","\n","  #НОРМАЛИЗАЦИЯ ТЕКСТОВ\n","  #убираем цифорки\n","  import string\n","  punctuation = string.punctuation\n","  numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"];\n","  #приводим к нижнему регистру\n","  text = sample_text.lower();\n","  #удаляем цифры\n","  text_no_numbers = ''.join(char for char in text if char not in numbers);\n","  #заменяем все символы пунктуации на пробелы\n","  translator = str.maketrans('', '', punctuation)\n","  normal_text = text_no_numbers.translate(translator)\n","  #Удаление лишних пробелов\n","  normal_text = ' '.join(normal_text.split())\n","  normal_text = normal_text.split()\n","  sum = len(normal_text)        #Считаем общее количество слов в тексте\n","\n","  # Анализ предложений\n","  print(\"Результаты анализа предложений:\")\n","  print(f\"Количество предложений: {len(sentences)}\")\n","  print(f\"Средняя длина предложения (в словах): {sum / len(sentences)}\")\n","  print(f\"Самое длинное предложение: {long_sentence}\")\n","  print(f\"Самое короткое предложение: {short_sentence}\")\n","\n","sample_text = \"\"\"Компьютерная лингвистика - это междисциплинарная область науки.\n","Она изучает математические и компьютерные модели естественного языка.\n","Методы компьютерной лингвистики применяются для решения различных задач, таких как машинный перевод, автоматическое реферирование и информационный поиск.\n","Современные алгоритмы позволяют анализировать большие объемы текстов.\"\"\"\n","\n","analyze_sentences(sample_text)\n","\n","\n"],"metadata":{"id":"QQd2ZgIj3YlJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760180704767,"user_tz":-240,"elapsed":39,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"e659a649-c339-49d7-f72a-86486c36bd57"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Результаты анализа предложений:\n","Количество предложений: 4\n","Средняя длина предложения (в словах): 9.5\n","Самое длинное предложение: Методы компьютерной лингвистики применяются для решения различных задач, таких как машинный перевод, автоматическое реферирование и информационный поиск.\n","Самое короткое предложение: Компьютерная лингвистика - это междисциплинарная область науки.\n"]}]},{"cell_type":"code","source":["english_text = \"\"\"Computational linguistics is an interdisciplinary field of science.\n","It studies mathematical and computational models of natural language.\n","Methods of computational linguistics are applied to solve various tasks such as machine translation, automatic summarization, and information retrieval.\n","Modern algorithms allow analyzing large volumes of texts.\"\"\"\n","\n","analyze_sentences(english_text)"],"metadata":{"id":"N7pW-9_c3rmI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1760180795431,"user_tz":-240,"elapsed":17,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"03984401-06a1-48b9-bbbe-3fccd3612961"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Результаты анализа предложений:\n","Количество предложений: 4\n","Средняя длина предложения (в словах): 11.0\n","Самое длинное предложение: Methods of computational linguistics are applied to solve various tasks such as machine translation, automatic summarization, and information retrieval.\n","Самое короткое предложение: Modern algorithms allow analyzing large volumes of texts.\n"]}]},{"cell_type":"markdown","source":["**5. Домашнее задание**"],"metadata":{"id":"ZE7TEjrM37te"}},{"cell_type":"markdown","source":["Напишите функцию для нормализации текста, которая:\n","\n","1. Приводит текст к нижнему регистру\n","2. Удаляет все знаки пунктуации\n","3. Заменяет все цифры на символ '#'\n","4. Удаляет лишние пробелы\n","\n","Напишите функцию, которая находит и выводит все слова из текста, содержащие гласные в определенной последовательности (например, 'о' и затем 'а').\n","\n","Создайте функцию, которая:\n","\n","1.   Токенизирует текст\n","2.   Отбирает только слова длиной более 4 символов\n","3. Сортирует их по алфавиту\n","4. Возвращает первые 10 слов\n","\n","Напишите функцию для анализа частотности символов в тексте, которая возвращает 5 самых часто встречающихся символов и их количество.\n","\n","Напишите программу, которая разделяет текст на параграфы (по двойному переносу строки), а затем подсчитывает для каждого параграфа: количество предложений, количество слов, среднюю длину слова"],"metadata":{"id":"qJtWAqaL3-od"}},{"cell_type":"markdown","source":["ПЕРВОЕ ДОМАШНЕЕ ЗАДАНИЕ\n","\n","\n","---\n","\n","\n","Напишите функцию для нормализации текста, которая:\n","\n","1. Приводит текст к нижнему регистру\n","2. Удаляет все знаки пунктуации\n","3. Заменяет все цифры на символ '#'\n","4. Удаляет лишние пробелы"],"metadata":{"id":"qzc1AuSAQQBx"}},{"cell_type":"code","source":["import re\n","def normalize_text_homework(sample_text):\n","  #Приводим текст к нижнему регистру\n","  text = sample_text.lower()\n","\n","  #Удаляем все знаки пунткуации\n","\n","  # Определение знаков пунктуации для удаления\n","  import string\n","  punctuation = string.punctuation  # !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n","\n","  #Удаление знаков пунткуации\n","  text_no_punctuation = ''.join(char for char in text if char not in punctuation)\n","\n","  #Заменяем все цифры на символ '#'\n","  text_no_numbers = re.sub(r'\\d', '#', text_no_punctuation)\n","\n","  #Удаляем лишние пробелы\n","  text_no_spaces = text_no_numbers.split()\n","  output_text = ' '.join(text_no_spaces)\n","  print(output_text)\n","\n","# Далее я попросил DeepSeek составить мне хаотичный текст\n","# с сумбурно расставленными знаками пунктуации, со скачущим регистром, и великим множеством цифр и кучей пробелов.\n","# Вот, что из этого вышло\n","sample_text = \"\"\"Привет!!!   Это   мой   ТЕКСТ для проверки  .  .  .  Он  должен  быть   ИСПОРЧЕН  всеми  способами:\n","1)  Тут  есть  цифры  123,  а  тут  4567   и  даже  890!!!\n","2)  Регистр  скачет  как  сумасшедший:  ОДИН,  два,  ТРИ,  четыре,  ПЯТЬ!!!\n","3)  Знаки  препинания  расставлены  невпопад  ,  ,  ? !  ...  А  может  ;  и  вот  так  :  —  или  так  –  !\n","4)  А  еще  тут  есть  дробные  числа  вроде  3.14  и  дата  01.01.2023  !!!\n","И  много-много     лишних      пробелов    везде!!!!\n","Проверь,  справится  ли  твоя  функция  с  этим  МЕСИВОМ  из  999  проблем???\"\"\"\n","\n","normalize_text_homework(sample_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yCXk6mxiPj4E","executionInfo":{"status":"ok","timestamp":1760180891441,"user_tz":-240,"elapsed":79,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"86658840-caca-4272-f8be-05b4200b5103"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stdout","text":["привет это мой текст для проверки он должен быть испорчен всеми способами # тут есть цифры ### а тут #### и даже ### # регистр скачет как сумасшедший один два три четыре пять # знаки препинания расставлены невпопад а может и вот так — или так – # а еще тут есть дробные числа вроде ### и дата ######## и многомного лишних пробелов везде проверь справится ли твоя функция с этим месивом из ### проблем\n"]}]},{"cell_type":"markdown","source":["ВТОРОЕ ДОМАШНЕЕ ЗАДАНИЕ\n","\n","\n","---\n","\n","\n","Напишите функцию, которая находит и выводит все слова из текста, содержащие гласные в определенной последовательности (например, 'о' и затем 'а').\n","\n","\n","*   Новый пункт\n","*   Новый пункт\n","\n"],"metadata":{"id":"Cm6kkPplYthD"}},{"cell_type":"code","source":["import re\n","import string\n","# Функция для для вывода слов с определенной последователньостью гласных\n","def words_with_two_syllables(X, Z, tokens):\n","  two_syllables_list = []\n","  pattern = f\"{X}.*{Z}\"\n","  for i in tokens:\n","    matches = re.findall(pattern, i)\n","    if matches:\n","      two_syllables_list.append(i)\n","  print(f'Слова с последовательностью гласных «{X}», «{Z}»: {two_syllables_list}')\n","\n","def tokenize_homework(deepseek_text):\n","  #НОРМАЛИЗАЦИЯ ТЕКСТА\n","  #убираем цифорки\n","  punctuation = string.punctuation\n","  numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"];\n","\n","  #приводим к нижнему регистру\n","  text = deepseek_text.lower();\n","\n","  #удаляем цифры\n","  text_no_numbers = ''.join(char for char in text if char not in numbers);\n","\n","  #заменяем все символы пунктуации на пробелы\n","  translator = str.maketrans('', '', punctuation)\n","  normal_text = text_no_numbers.translate(translator)\n","\n","  #Удаление лишних пробелов\n","  normal_text = ' '.join(normal_text.split())\n","\n","  #ТОКЕНИЗАЦИЯ ТЕКСТОВ\n","\n","  #Токенизация по пробелам\n","  tokens = normal_text.split()\n","\n","  return tokens\n","\n","deepseek_text = \"\"\"Моя любимая бабушка жила в деревне, и каждое лето я приезжал к ней. Помню, как однажды стояла прекрасная погода,\n","когда мы пошли по пыльной дороге на её пасеку. По пути мы видели корову, которая мирно жевала траву под большим деревом.\n","Бабушка несла в руках тарелку со свежим мёдом, но внезапно споткнулась о камень и чуть не уронила её.\n","К счастью, она успела ухватиться за старые перила у колодца, избежав падения.\n","В её маленькой комнате висела старая фотография: карета, запряжённая лошадьми,\n","едет по берегу океана. Это была история из её молодости. Бабушка любила делиться этими воспоминаниями,\n","и я готов был верить каждому её слову.\n","Каждое утро она заводила свою старую программу на радио, пока белила стены дома.\n","\"Нужно успеть белить до дождя\", — говорила она, замешивая раствор. Я наблюдал, как она ловко\n","месит известку своими натруженными руками, один палец которой был всегда в мелкой царапине от пчёл.\n","В местной школе, куда я ходил, была моя заветная мечта — стать путешественником.\n","Но главной моей работой тогда было помогать бабушке, и я не рассматрил это как бегство от обязанностей.\n","Деревенское заведение, где мы иногда покупали продукты, до сих пор стоит на том же месте.\n","\"\"\"\n","\n","tokens = tokenize_homework(deepseek_text)\n","\n","#Слова с последовательностью гласных «А», «У»\n","words_with_two_syllables(\"а\", \"у\", tokens)\n","\n","#Слова с последовательностью гласных «А», «Е»\n","words_with_two_syllables(\"а\", \"е\", tokens)\n","\n","#Слова с последовательностью гласных «Е», «И»\n","words_with_two_syllables(\"е\", \"и\", tokens)\n","\n","#Слова с последовательностью гласных «А», «О»\n","words_with_two_syllables(\"а\", \"о\", tokens)\n","\n","#Слова с последовательностью гласных «Е», «О»\n","words_with_two_syllables(\"е\", \"о\", tokens)\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VOexd0sAavyO","executionInfo":{"status":"ok","timestamp":1760181051039,"user_tz":-240,"elapsed":58,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"1ab3a5a2-07a2-446c-a355-e7e59145bf5b"},"execution_count":19,"outputs":[{"output_type":"stream","name":"stdout","text":["Слова с последовательностью гласных «а», «у»: ['бабушка', 'пасеку', 'траву', 'бабушка', 'тарелку', 'бабушка', 'каждому', 'старую', 'программу', 'натруженными', 'бабушке']\n","Слова с последовательностью гласных «а», «е»: ['каждое', 'пасеку', 'тарелку', 'камень', 'старые', 'падения', 'маленькой', 'комнате', 'карета', 'каждое', 'замешивая', 'натруженными', 'палец', 'царапине', 'заветная', 'бабушке', 'обязанностей', 'заведение']\n","Слова с последовательностью гласных «е», «и»: ['видели', 'свежим', 'перила', 'падения', 'делиться', 'верить', 'белила', 'белить', 'замешивая', 'месит', 'натруженными', 'путешественником', 'заведение']\n","Слова с последовательностью гласных «а», «о»: ['каждое', 'внезапно', 'маленькой', 'каждому', 'каждое', 'заводила', 'радио', 'раствор', 'главной', 'работой', 'обязанностей']\n","Слова с последовательностью гласных «е», «о»: ['лето', 'деревом', 'внезапно', 'маленькой', 'мелкой', 'местной', 'путешественником', 'бегство', 'деревенское']\n"]}]},{"cell_type":"markdown","source":["ТРЕТЬЕ ДОМАШНЕЕ ЗАДАНИЕ\n","\n","\n","---\n","\n","\n","Создайте функцию, которая:\n","\n","1. Токенизирует текст\n","2. Отбирает только слова длиной более 4 символов\n","3. Сортирует их по алфавиту\n","4. Возвращает первые 10 слов\n"],"metadata":{"id":"mUORHmOz-fj8"}},{"cell_type":"code","source":["def first_ten_words(deepseek_text):\n","  #НОРМАЛИЗАЦИЯ ТЕКСТА\n","  #убираем цифорки\n","  import string\n","  punctuation = string.punctuation\n","  numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"];\n","\n","  #приводим к нижнему регистру\n","  text = deepseek_text.lower();\n","\n","  #удаляем цифры\n","  text_no_numbers = ''.join(char for char in text if char not in numbers);\n","\n","  #заменяем все символы пунктуации на пробелы\n","  translator = str.maketrans('', '', punctuation)\n","  normal_text = text_no_numbers.translate(translator)\n","\n","  #Удаление лишних пробелов\n","  normal_text = ' '.join(normal_text.split())\n","\n","  #ТОКЕНИЗАЦИЯ ТЕКСТОВ\n","\n","  #Токенизация по пробелам\n","  tokens = normal_text.split()\n","\n","  #Отбираем слова длиной более 4 символов\n","  four_letter_words = []\n","  for i in tokens:\n","    if len(i) > 4 and i not in four_letter_words:\n","      four_letter_words.append(i)\n","  four_letter_words.sort() #Сортируем по алфавиту\n","  print(four_letter_words[:10]) # Выводим первые 10 слов\n","\n","deepseek_text = \"\"\"Моя любимая бабушка жила в деревне, и каждое лето я приезжал к ней. Помню, как однажды стояла прекрасная погода,\n","когда мы пошли по пыльной дороге на её пасеку. По пути мы видели корову, которая мирно жевала траву под большим деревом.\n","Бабушка несла в руках тарелку со свежим мёдом, но внезапно споткнулась о камень и чуть не уронила её.\n","К счастью, она успела ухватиться за старые перила у колодца, избежав падения.\n","В её маленькой комнате висела старая фотография: карета, запряжённая лошадьми,\n","едет по берегу океана. Это была история из её молодости. Бабушка любила делиться этими воспоминаниями,\n","и я готов был верить каждому её слову.\n","Каждое утро она заводила свою старую программу на радио, пока белила стены дома.\n","\"Нужно успеть белить до дождя\", — говорила она, замешивая раствор. Я наблюдал, как она ловко\n","месит известку своими натруженными руками, один палец которой был всегда в мелкой царапине от пчёл.\n","В местной школе, куда я ходил, была моя заветная мечта — стать путешественником.\n","Но главной моей работой тогда было помогать бабушке, и я не рассматрил это как бегство от обязанностей.\n","Деревенское заведение, где мы иногда покупали продукты, до сих пор стоит на том же месте.\n","\"\"\"\n","\n","first_ten_words(deepseek_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q3eC9mlp6cQw","executionInfo":{"status":"ok","timestamp":1760181120054,"user_tz":-240,"elapsed":51,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"eeac55b2-453c-4b15-db8e-08bb4c8dc37a"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["['бабушка', 'бабушке', 'бегство', 'белила', 'белить', 'берегу', 'большим', 'верить', 'видели', 'висела']\n"]}]},{"cell_type":"markdown","source":["ЧЕТВЕРТОЕ ДОМАШНЕЕ ЗАДАНИЕ\n","\n","\n","---\n","Напишите функцию для анализа частотности символов в тексте, которая возвращает\n","5 самых часто встречающихся символов и их количество."],"metadata":{"id":"IcnCCH4N-xjY"}},{"cell_type":"code","source":["import string\n","def most_frequent_chars(deepseek_text):\n","  #НОРМАЛИЗАЦИЯ ТЕКСТА\n","  #убираем цифорки\n","  punctuation = string.punctuation\n","  numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"];\n","\n","  #приводим к нижнему регистру\n","  text = deepseek_text.lower();\n","\n","  #удаляем цифры\n","  text_no_numbers = ''.join(char for char in text if char not in numbers);\n","\n","  #заменяем все символы пунктуации на пробелы\n","  translator = str.maketrans('', '', punctuation)\n","  normal_text = text_no_numbers.translate(translator)\n","\n","  #Удаление лишних пробелов\n","  normal_text = ' '.join(normal_text.split())\n","\n","  #ТОКЕНИЗАЦИЯ ТЕКСТОВ\n","\n","  #Токенизация по пробелам\n","  tokens = normal_text.split()\n","\n","  #Кладем в словарь частотность каждого символа\n","  char_dict = {}\n","  for i in tokens:\n","    for char in i:\n","      if char in char_dict.keys():\n","        char_dict[char]+=1;\n","      else:\n","        char_dict[char] = 1;\n","\n","  #Ищем самые частоупотребимые символы\n","  sorted_items_desc = sorted(char_dict.items(), key=lambda item: item[1], reverse=True)\n","  print(f\"Самые частоупотребимые символы: {sorted_items_desc[:5]}\")\n","\n","deepseek_text = \"\"\"Моя любимая бабушка жила в деревне, и каждое лето я приезжал к ней. Помню, как однажды стояла прекрасная погода,\n","когда мы пошли по пыльной дороге на её пасеку. По пути мы видели корову, которая мирно жевала траву под большим деревом.\n","Бабушка несла в руках тарелку со свежим мёдом, но внезапно споткнулась о камень и чуть не уронила её.\n","К счастью, она успела ухватиться за старые перила у колодца, избежав падения.\n","В её маленькой комнате висела старая фотография: карета, запряжённая лошадьми,\n","едет по берегу океана. Это была история из её молодости. Бабушка любила делиться этими воспоминаниями,\n","и я готов был верить каждому её слову.\n","Каждое утро она заводила свою старую программу на радио, пока белила стены дома.\n","\"Нужно успеть белить до дождя\", — говорила она, замешивая раствор. Я наблюдал, как она ловко\n","месит известку своими натруженными руками, один палец которой был всегда в мелкой царапине от пчёл.\n","В местной школе, куда я ходил, была моя заветная мечта — стать путешественником.\n","Но главной моей работой тогда было помогать бабушке, и я не рассматрил это как бегство от обязанностей.\n","Деревенское заведение, где мы иногда покупали продукты, до сих пор стоит на том же месте.\n","\"\"\"\n","\n","most_frequent_chars(deepseek_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8XkQ3E7x-wWs","executionInfo":{"status":"ok","timestamp":1760181209541,"user_tz":-240,"elapsed":62,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"a3ca38bf-d0d1-4edc-91ee-4754afb95ce7"},"execution_count":22,"outputs":[{"output_type":"stream","name":"stdout","text":["Самые частоупотребимые символы: [('о', 104), ('а', 102), ('е', 77), ('и', 56), ('т', 55)]\n"]}]},{"cell_type":"markdown","source":["ПЯТОЕ ДОМАШНЕЕ ЗАДАНИЕ\n","\n","\n","---\n","\n","\n","Напишите программу, которая разделяет текст на параграфы (по двойному переносу строки), а затем подсчитывает для каждого параграфа: количество предложений, количество слов, среднюю длину слова"],"metadata":{"id":"UHWzG288_0HF"}},{"cell_type":"code","source":["import re\n","import string\n","\n","def simple_sentence_tokenize(text):\n","    \"\"\"\n","    Простая токенизация на предложения:\n","    1. Заменяем знаки конца предложения на специальный маркер\n","    2. Разделяем текст по маркеру\n","    3. Очищаем полученные предложения\n","    \"\"\"\n","    # Заменяем знаки конца предложения\n","    for end_mark in ['.', '!', '?']:\n","        text = text.replace(end_mark, f'{end_mark}SENTENCE_END')\n","\n","    # Разделяем по маркеру\n","    sentences = text.split('SENTENCE_END')\n","\n","    # Очищаем предложения и удаляем пустые\n","    cleaned_sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n","    return cleaned_sentences\n","\n","def analyze_paragraphs(text):\n","    \"\"\"\n","    Разделяет текст на параграфы и анализирует каждый параграф.\n","    \"\"\"\n","    paragraphs = text.split('\\n\\n')\n","\n","    for i, paragraph in enumerate(paragraphs):\n","        sentences = simple_sentence_tokenize(paragraph)\n","        number_of_sentences = len(sentences)\n","        total_number_of_words = 0\n","        sum = 0\n","        for sentence in sentences:\n","            # Нормализация и токенизация слов внутри предложения\n","            #НОРМАЛИЗАЦИЯ ТЕКСТА\n","            #убираем цифорки\n","            punctuation = string.punctuation\n","            numbers = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"0\"];\n","\n","            #приводим к нижнему регистру\n","            sentence = sentence.lower();\n","\n","            #удаляем цифры\n","            text_no_numbers = ''.join(char for char in sentence if char not in numbers);\n","\n","            #заменяем все символы пунктуации на пробелы\n","            translator = str.maketrans('', '', punctuation)\n","            normal_text = text_no_numbers.translate(translator)\n","\n","            #Удаление лишних пробелов\n","            normal_text = ' '.join(normal_text.split())\n","\n","            #Токенизация по пробелам\n","            tokens = normal_text.split()\n","            number_of_words = len(tokens)\n","            total_number_of_words += number_of_words\n","            for token in tokens:\n","                sum += len(token)\n","        print(f\"Параграф {i + 1}:\\n Количество предложнний: {number_of_sentences}\\n Количество слов: {total_number_of_words}\\n Средняя длина слова: {sum / total_number_of_words}\")\n","\n","deepseek_text = \"\"\"Моя любимая бабушка жила в деревне, и каждое лето я приезжал к ней. Помню, как однажды стояла прекрасная погода,\n","когда мы пошли по пыльной дороге на её пасеку. По пути мы видели корову, которая мирно жевала траву под большим деревом.\n","Бабушка несла в руках тарелку со свежим мёдом, но внезапно споткнулась о камень и чуть не уронила её.\n","К счастью, она успела ухватиться за старые перила у колодца, избежав падения.\n","В её маленькой комнате висела старая фотография: карета, запряжённая лошадьми,\n","едет по берегу океана.\n","\n","Это была история из её молодости. Бабушка любила делиться этими воспоминаниями,\n","и я готов был верить каждому её слову.\n","Каждое утро она заводила свою старую программу на радио, пока белила стены дома.\n","\"Нужно успеть белить до дождя\", — говорила она, замешивая раствор. Я наблюдал, как она ловко\n","месит известку своими натруженными руками, один палец которой был всегда в мелкой царапине от пчёл.\n","\n","В местной школе, куда я ходил, была моя заветная мечта — стать путешественником.\n","Но главной моей работой тогда было помогать бабушке, и я не рассматрил это как бегство от обязанностей.\n","Деревенское заведение, где мы иногда покупали продукты, до сих пор стоит на том же месте..\"\"\"\n","\n","analyze_paragraphs(deepseek_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1759924497765,"user_tz":-240,"elapsed":61,"user":{"displayName":"Миша Кононов","userId":"04606632895907194736"}},"outputId":"2a3b6130-a410-41f6-916e-76c9e12c2560","id":"OCUBDRpQqpQo"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Параграф 1:\n"," Количество предложнний: 6\n"," Количество слов: 84\n"," Средняя длина слова: 4.9523809523809526\n","Параграф 2:\n"," Количество предложнний: 5\n"," Количество слов: 62\n"," Средняя длина слова: 5.129032258064516\n","Параграф 3:\n"," Количество предложнний: 4\n"," Количество слов: 45\n"," Средняя длина слова: 4.933333333333334\n"]}]}]}