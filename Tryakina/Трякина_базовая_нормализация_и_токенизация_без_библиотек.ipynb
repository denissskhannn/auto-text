{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaCyWYJ6uGfk"
      },
      "source": [
        "В этом ноутбуке вы узнаете:\n",
        "\n",
        "1.   Как использовать встроенные методы Python для работы со строками\n",
        "2.   Как выполнять базовую нормализацию текста\n",
        "3. Как токенизировать текст с помощью простых методов\n",
        "4. Как применять эти навыки на практике\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4-yFhGcy934"
      },
      "source": [
        "**1. Основные понятия и функции**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mMYBk9PluRfs"
      },
      "source": [
        "В Python текст представлен в виде строк (тип данных str). Строки можно создавать, используя одинарные или двойные кавычки."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXalOImZuMdk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58959eb8-0244-4cc9-be99-3afd09ea6c76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Это текст в \"одинарных\" кавычках\n",
            "Это текст в 'двойных' кавычках\n",
            "Это текст в \"тройных\" кавычках\n",
            "Это\n",
            "текст\n",
            "в 'тройных'\n",
            "кавычках\n"
          ]
        }
      ],
      "source": [
        "# Создание строк\n",
        "text1 = 'Это текст в \"одинарных\" кавычках'\n",
        "text2 = \"Это текст в 'двойных' кавычках\"\n",
        "text3 = '''Это текст в \"тройных\" кавычках'''\n",
        "text4 = '''Это\n",
        "текст\n",
        "в 'тройных'\n",
        "кавычках'''\n",
        "\n",
        "# Вывод строк\n",
        "print(text1)\n",
        "print(text2)\n",
        "print(text3)\n",
        "print(text4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dVUdNKvuYvU"
      },
      "source": [
        "1.1. Индексация и срезы строк.\n",
        "Строки в Python — это последовательности символов, к которым можно обращаться по индексу. Индексация начинается с 0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8RlZDm97uVrC"
      },
      "outputs": [],
      "source": [
        "# Строка для примеров\n",
        "sample_text = \"Компьютерная лингвистика\"\n",
        "\n",
        "# Получение отдельного символа\n",
        "print(\"Первый символ:\", sample_text[0])\n",
        "print(\"Пятый символ:\", sample_text[4])\n",
        "\n",
        "# Срезы строк\n",
        "print(\"Первые 12 символов:\", sample_text[:12])  # от начала до 12-го символа (не включая)\n",
        "print(\"С 13-го символа до конца:\", sample_text[13:])  # с 13-го символа до конца\n",
        "print(\"С 5-го по 10-й символ:\", sample_text[5:11])  # с 5-го по 10-й символ (11-й не включается)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oi1N22TvbQx"
      },
      "source": [
        "1.2. Основные методы строк\n",
        "Python предоставляет множество встроенных методов для работы со строками. Рассмотрим наиболее полезные для обработки текста:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkcKQqqgvcpk"
      },
      "outputs": [],
      "source": [
        "# Строка для примеров\n",
        "text = \"   Пример текста для анализа.   \"\n",
        "\n",
        "# Удаление пробелов в начале и конце строки\n",
        "print(\"После strip():\", text.strip())\n",
        "\n",
        "# Перевод в нижний регистр\n",
        "print(\"После lower():\", text.lower())\n",
        "\n",
        "# Перевод в верхний регистр\n",
        "print(\"После upper():\", text.upper())\n",
        "\n",
        "# Проверка, начинается ли строка с определенной подстроки\n",
        "print(\"Начинается с 'Пример'?\", text.strip().startswith(\"Пример\"))\n",
        "\n",
        "# Проверка, заканчивается ли строка определенной подстрокой\n",
        "print(\"Заканчивается на '.'?\", text.strip().endswith(\".\"))\n",
        "\n",
        "# Замена подстроки\n",
        "print(\"После replace():\", text.replace(\"анализа\", \"обработки\"))\n",
        "\n",
        "# Подсчет вхождений подстроки\n",
        "print(\"Количество пробелов:\", text.count(\" \"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-oEf7vLCvvzL"
      },
      "source": [
        "1.3. Конкатенация строк и форматирование.\n",
        "Существует несколько способов объединения строк в Python:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CS50TkzKvwfk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f67f5ba0-9fd2-4fb9-b9a8-1543274c0ddb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Полное имя: Иван Петров\n",
            "Меня зовут Иван Петров, мне 25 лет.\n",
            "Меня зовут Иван Петров, мне 25 лет.\n",
            "Меня зовут Иван Петров, мне 25 лет.\n"
          ]
        }
      ],
      "source": [
        "# Простая конкатенация с помощью оператора +\n",
        "first_name = \"Иван\"\n",
        "last_name = \"Петров\"\n",
        "full_name = first_name + \" \" + last_name\n",
        "print(\"Полное имя:\", full_name)\n",
        "\n",
        "# Форматирование строк с помощью метода format()\n",
        "age = 25\n",
        "message = \"Меня зовут {}, мне {} лет.\".format(full_name, age)\n",
        "print(message)\n",
        "\n",
        "# f-строки (начиная с Python 3.6)\n",
        "message_f = f\"Меня зовут {full_name}, мне {age} лет.\"\n",
        "print(message_f)\n",
        "\n",
        "# Использование %\n",
        "message_old = \"Меня зовут %s, мне %d лет.\" % (full_name, age)\n",
        "print(message_old)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0K6mt6Vv6gV"
      },
      "source": [
        "**2. Базовая нормализация текста**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hL2BXNo8wEVY"
      },
      "source": [
        "Нормализация текста — это процесс преобразования текста к стандартному виду для облегчения его дальнейшей обработки. Рассмотрим базовые операции нормализации."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5Gk1AnRwHK0"
      },
      "source": [
        "2.1. Приведение к нижнему регистру помогает унифицировать текст. Обычно используется нижний регистр."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNNMpCqOv2Dz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df36125-dc9c-40b3-cedf-5a900aa0bc29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный текст: КомпьЮтерная ЛИНГвистика изучает Методы Автоматической Обработки Текста.\n",
            "Нормализованный текст: компьютерная лингвистика изучает методы автоматической обработки текста.\n",
            "Английский текст после нормализации: natural language processing (nlp) is a field of ai.\n"
          ]
        }
      ],
      "source": [
        "# Пример текста с разным регистром\n",
        "mixed_case_text = \"КомпьЮтерная ЛИНГвистика изучает Методы Автоматической Обработки Текста.\"\n",
        "\n",
        "# Приведение к нижнему регистру\n",
        "normalized_text = mixed_case_text.lower()\n",
        "print(\"Исходный текст:\", mixed_case_text)\n",
        "print(\"Нормализованный текст:\", normalized_text)\n",
        "\n",
        "# Пример на английском\n",
        "english_text = \"Natural Language Processing (NLP) is a FIELD of AI.\"\n",
        "print(\"Английский текст после нормализации:\", english_text.lower())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vlwzl4-bw7u9"
      },
      "source": [
        "2.2. Удаление лишних пробелов. Часто тексты содержат лишние пробелы, которые нужно удалить.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AioDUYPrw-Hl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "455f3c4a-7452-44d0-e2c6-a2a24f8398a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "После strip(): В  этом   тексте  есть  лишние    пробелы.\n",
            "Нормализация: В этом тексте есть лишние пробелы.\n",
            "Английский текст после нормализации пробелов: This text has extra spaces.\n"
          ]
        }
      ],
      "source": [
        "# Текст с лишними пробелами\n",
        "text_with_spaces = \"   В  этом   тексте  есть  лишние    пробелы.   \"\n",
        "\n",
        "# Удаление пробелов в начале и конце\n",
        "trimmed_text = text_with_spaces.strip()\n",
        "print(\"После strip():\", trimmed_text)\n",
        "\n",
        "words = trimmed_text.split()  # Разбиваем текст на слова\n",
        "normalized_manually = ' '.join(words)  # Объединяем слова с одним пробелом\n",
        "print(\"Нормализация:\", normalized_manually)\n",
        "\n",
        "# Пример на английском\n",
        "english_spaces = \"  This   text   has   extra   spaces. \"\n",
        "english_normalized = ' '.join(english_spaces.strip().split())\n",
        "print(\"Английский текст после нормализации пробелов:\", english_normalized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7bFiY8syfRf"
      },
      "source": [
        "2.3. Удаление пунктуации. Для многих задач обработки текста необходимо удалить знаки пунктуации."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g7M5Bna1yjB1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "630aed78-ba75-43a6-ad48-020461c4e146"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Знаки пунктуации: !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "Текст без пунктуации (метод 1): Привет мир Как дела Это  пример текста с разными знаками пунктуации\n",
            "Текст без пунктуации (метод 2): Привет мир Как дела Это  пример текста с разными знаками пунктуации\n",
            "Английский текст без пунктуации: Hello world How are you This is a sample text with various punctuation marks\n"
          ]
        }
      ],
      "source": [
        "# Текст с пунктуацией\n",
        "text_with_punctuation = \"Привет, мир! Как дела? Это - пример текста; с разными знаками пунктуации.\"\n",
        "\n",
        "# Определение знаков пунктуации для удаления\n",
        "import string\n",
        "punctuation = string.punctuation  # !\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
        "print(\"Знаки пунктуации:\", punctuation)\n",
        "\n",
        "# Удаление пунктуации (метод 1)\n",
        "no_punctuation = ''.join(char for char in text_with_punctuation if char not in punctuation)\n",
        "print(\"Текст без пунктуации (метод 1):\", no_punctuation)\n",
        "\n",
        "# Удаление пунктуации (метод 2)\n",
        "translator = str.maketrans('', '', punctuation)\n",
        "no_punctuation2 = text_with_punctuation.translate(translator)\n",
        "print(\"Текст без пунктуации (метод 2):\", no_punctuation2)\n",
        "\n",
        "# Пример на английском\n",
        "english_punctuation = \"Hello, world! How are you? This is a sample text; with various punctuation marks.\"\n",
        "english_no_punctuation = english_punctuation.translate(translator)\n",
        "print(\"Английский текст без пунктуации:\", english_no_punctuation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cCzDj3GayrSf"
      },
      "source": [
        "2.4. Комплексная нормализация текста. Объединим все изученные методы для комплексной нормализации текста."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EQfaUxNyuOm"
      },
      "outputs": [],
      "source": [
        "def normalize_text(text):\n",
        "    \"\"\"\n",
        "    Функция для комплексной нормализации текста:\n",
        "    1. Приведение к нижнему регистру\n",
        "    2. Удаление лишних пробелов\n",
        "    3. Удаление пунктуации\n",
        "    \"\"\"\n",
        "    # Шаг 1: Приведение к нижнему регистру\n",
        "    text = text.lower()\n",
        "\n",
        "    # Шаг 2: Удаление пунктуации\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    # Шаг 3: Удаление лишних пробелов\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "# Проверка функции на русском тексте\n",
        "russian_text = \"   Компьютерная    ЛИНГВИСТИКА - это ОБЛАСТЬ науки, изучающая   методы автоматической    обработки текста!   \"\n",
        "normalized_russian = normalize_text(russian_text)\n",
        "print(\"Исходный русский текст:\", russian_text)\n",
        "print(\"Нормализованный русский текст:\", normalized_russian)\n",
        "\n",
        "# Проверка функции на английском тексте\n",
        "english_text = \"   Natural    LANGUAGE Processing (NLP) - is a FIELD of AI, focusing   on text analysis!   \"\n",
        "normalized_english = normalize_text(english_text)\n",
        "print(\"Исходный английский текст:\", english_text)\n",
        "print(\"Нормализованный английский текст:\", normalized_english)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2IvHG_yy1uJ"
      },
      "source": [
        "**3. Простая токенизация текста**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISndfr9tzMRC"
      },
      "source": [
        "Токенизация — это процесс разделения текста на отдельные токены (обычно слова или предложения). Рассмотрим простые методы токенизации с использованием встроенных возможностей Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjvNUNImzP5i"
      },
      "source": [
        "3.1. Токенизация по пробелам. Самый простой способ токенизации — разделение текста по пробелам с помощью метода .split()."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRMRYdZfzTk2"
      },
      "outputs": [],
      "source": [
        "# Пример текста\n",
        "text = \"Компьютерная лингвистика изучает методы обработки текста\"\n",
        "\n",
        "# Токенизация по пробелам\n",
        "tokens = text.split()\n",
        "print(\"Токены:\", tokens)\n",
        "print(\"Количество токенов:\", len(tokens))\n",
        "\n",
        "# Токенизация английского текста\n",
        "english_text = \"Natural language processing studies methods of text analysis\"\n",
        "english_tokens = english_text.split()\n",
        "print(\"Английские токены:\", english_tokens)\n",
        "print(\"Количество английских токенов:\", len(english_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ey-4jl42zahC"
      },
      "source": [
        "3.2. Токенизация с учетом пунктуации. Токенизация по пробелам не учитывает пунктуацию. Для более точной токенизации можно сначала отделить пунктуацию от слов."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8rYkdzlnzdkp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "124f2c1c-85aa-43bc-b302-444875d20ca8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Русский текст: Привет, мир! Как дела? Это - пример текста; с разными знаками пунктуации.\n",
            "Токены русского текста: ['Привет', ',', 'мир', '!', 'Как', 'дела', '?', 'Это', '-', 'пример', 'текста', ';', 'с', 'разными', 'знаками', 'пунктуации', '.']\n",
            "Количество токенов: 17\n",
            "Английский текст: Hello, world! How are you? This is a sample text; with various punctuation marks.\n",
            "Токены английского текста: ['Hello', ',', 'world', '!', 'How', 'are', 'you', '?', 'This', 'is', 'a', 'sample', 'text', ';', 'with', 'various', 'punctuation', 'marks', '.']\n",
            "Количество токенов: 19\n"
          ]
        }
      ],
      "source": [
        "def simple_tokenize(text):\n",
        "    \"\"\"\n",
        "    Простая токенизация с учетом пунктуации:\n",
        "    1. Добавляем пробелы вокруг знаков пунктуации\n",
        "    2. Разделяем по пробелам\n",
        "    3. Удаляем пустые токены\n",
        "    \"\"\"\n",
        "    # Добавляем пробелы вокруг знаков пунктуации\n",
        "    for punct in string.punctuation:\n",
        "        text = text.replace(punct, f' {punct} ')\n",
        "\n",
        "    # Разделяем по пробелам и удаляем пустые токены\n",
        "    tokens = [token for token in text.split() if token]\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Проверка на русском тексте\n",
        "russian_text = \"Привет, мир! Как дела? Это - пример текста; с разными знаками пунктуации.\"\n",
        "russian_tokens = simple_tokenize(russian_text)\n",
        "print(\"Русский текст:\", russian_text)\n",
        "print(\"Токены русского текста:\", russian_tokens)\n",
        "print(\"Количество токенов:\", len(russian_tokens))\n",
        "\n",
        "# Проверка на английском тексте\n",
        "english_text = \"Hello, world! How are you? This is a sample text; with various punctuation marks.\"\n",
        "english_tokens = simple_tokenize(english_text)\n",
        "print(\"Английский текст:\", english_text)\n",
        "print(\"Токены английского текста:\", english_tokens)\n",
        "print(\"Количество токенов:\", len(english_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qfbRKk1S0wq_"
      },
      "source": [
        "3.3. Токенизация предложений. Простой способ — разделение по знакам конца предложения."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bw3dAKeG0-fA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e7ff13a-05d5-443e-e314-8d0bcb88068b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Русский текст: Привет, мир! Как дела? Это пример текста. Он состоит из нескольких предложений.\n",
            "Предложения русского текста:\n",
            "1. Привет, мир!\n",
            "2. Как дела?\n",
            "3. Это пример текста.\n",
            "4. Он состоит из нескольких предложений.\n",
            "\n",
            "Английский текст: Hello, world! How are you? This is a sample text. It consists of several sentences.\n",
            "Предложения английского текста:\n",
            "1. Hello, world!\n",
            "2. How are you?\n",
            "3. This is a sample text.\n",
            "4. It consists of several sentences.\n"
          ]
        }
      ],
      "source": [
        "def simple_sentence_tokenize(text):\n",
        "    \"\"\"\n",
        "    Простая токенизация на предложения:\n",
        "    1. Заменяем знаки конца предложения на специальный маркер\n",
        "    2. Разделяем текст по маркеру\n",
        "    3. Очищаем полученные предложения\n",
        "    \"\"\"\n",
        "    # Заменяем знаки конца предложения\n",
        "    for end_mark in ['.', '!', '?']:\n",
        "        text = text.replace(end_mark, f'{end_mark}SENTENCE_END')\n",
        "\n",
        "    # Разделяем по маркеру\n",
        "    sentences = text.split('SENTENCE_END')\n",
        "\n",
        "    # Очищаем предложения и удаляем пустые\n",
        "    cleaned_sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "\n",
        "    return cleaned_sentences\n",
        "\n",
        "# Проверка на русском тексте\n",
        "russian_text = \"Привет, мир! Как дела? Это пример текста. Он состоит из нескольких предложений.\"\n",
        "russian_sentences = simple_sentence_tokenize(russian_text)\n",
        "print(\"Русский текст:\", russian_text)\n",
        "print(\"Предложения русского текста:\")\n",
        "for i, sentence in enumerate(russian_sentences, 1):\n",
        "    print(f\"{i}. {sentence}\")\n",
        "\n",
        "# Проверка на английском тексте\n",
        "english_text = \"Hello, world! How are you? This is a sample text. It consists of several sentences.\"\n",
        "english_sentences = simple_sentence_tokenize(english_text)\n",
        "print(\"\\nАнглийский текст:\", english_text)\n",
        "print(\"Предложения английского текста:\")\n",
        "for i, sentence in enumerate(english_sentences, 1):\n",
        "    print(f\"{i}. {sentence}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_a-rRcLp1NnW"
      },
      "source": [
        "3.4. Объединение токенов обратно в текст. Метод .join() позволяет объединить токены обратно в текст, указав разделитель."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jCOkR50y1PYv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c16abe8-6199-45d9-8a12-05c6b7958c60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Объединенный текст: Компьютерная лингвистика изучает методы обработки текста\n",
            "Токены через запятую: Компьютерная, лингвистика, изучает, методы, обработки, текста\n",
            "Объединенный английский текст: Natural language processing studies methods of text analysis\n"
          ]
        }
      ],
      "source": [
        "# Пример токенов\n",
        "tokens = [\"Компьютерная\", \"лингвистика\", \"изучает\", \"методы\", \"обработки\", \"текста\"]\n",
        "\n",
        "# Объединение токенов с пробелом\n",
        "text = ' '.join(tokens)\n",
        "print(\"Объединенный текст:\", text)\n",
        "\n",
        "# Объединение с другими разделителями\n",
        "comma_separated = ', '.join(tokens)\n",
        "print(\"Токены через запятую:\", comma_separated)\n",
        "\n",
        "# Объединение английских токенов\n",
        "english_tokens = [\"Natural\", \"language\", \"processing\", \"studies\", \"methods\", \"of\", \"text\", \"analysis\"]\n",
        "english_text = ' '.join(english_tokens)\n",
        "print(\"Объединенный английский текст:\", english_text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTAF-Lj21evo"
      },
      "source": [
        "**4. Практические упражнения**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ffDLEVL1oiZ"
      },
      "source": [
        "Упражнение 1: Нормализация текста. Напишите функцию, которая будет нормализовать текст следующим образом:\n",
        "\n",
        "1. Привести к нижнему регистру\n",
        "2. Удалить все цифры\n",
        "3. Заменить все символы пунктуации на пробелы\n",
        "4. Удалить лишние пробелы\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU4ZTUrd1jFX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9659ce90-4682-4416-fbd6-2c243a762080"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный текст: Пример текста123, с РАЗНЫМИ символами! И 456 цифрами?!\n",
            "Нормализованный текст: пример текста с разными символами и цифрами\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    text = ''.join(char for char in text if char not in string.digits)\n",
        "\n",
        "    for punct in ['.', ',', '!', '?']:\n",
        "        text = text.replace(punct, ' ')\n",
        "\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "sample_text = \"Пример текста123, с РАЗНЫМИ символами! И 456 цифрами?!\"\n",
        "normalized_text = normalize_text(sample_text)\n",
        "print(\"Исходный текст:\", sample_text)\n",
        "print(\"Нормализованный текст:\", normalized_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waC9ZHWB2Kph"
      },
      "source": [
        "Упражнение 2: Подсчет частотности слов. Напишите функцию, которая будет принимать текст, нормализовать его, токенизировать и возвращать словарь с частотностью каждого слова."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HlWO9Bpn2SQo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c5acd13-7f87-4c11-da25-e338452b4800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный русский текст: Компьютерная лингвистика изучает методы обработки текста. Компьютерная лингвистика является областью искусственного интеллекта.\n",
            "Частотность слов в русском тексте: {'компьютерная': 2, 'лингвистика': 2, 'изучает': 1, 'методы': 1, 'обработки': 1, 'текста': 1, 'является': 1, 'областью': 1, 'искусственного': 1, 'интеллекта': 1}\n",
            "\n",
            "Исходный английский текст: Natural language processing is a field of artificial intelligence. Natural language processing focuses on the interaction between computers and humans.\n",
            "Частотность слов в английском тексте: {'natural': 2, 'language': 2, 'processing': 2, 'is': 1, 'a': 1, 'field': 1, 'of': 1, 'artificial': 1, 'intelligence': 1, 'focuses': 1, 'on': 1, 'the': 1, 'interaction': 1, 'between': 1, 'computers': 1, 'and': 1, 'humans': 1}\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text = text.translate(translator)\n",
        "\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "def tokenize_text(text):\n",
        "    normalized_text = normalize_text(text)\n",
        "    tokens = normalized_text.split()\n",
        "    word_freq = {}\n",
        "\n",
        "    for token in tokens:\n",
        "        if token in word_freq:\n",
        "            word_freq[token] += 1\n",
        "        else:\n",
        "            word_freq[token] = 1\n",
        "\n",
        "    return word_freq\n",
        "\n",
        "sample_text = \"Компьютерная лингвистика изучает методы обработки текста. Компьютерная лингвистика является областью искусственного интеллекта.\"\n",
        "russian_freq = tokenize_text(sample_text)\n",
        "print(\"Исходный русский текст:\", sample_text)\n",
        "print(\"Частотность слов в русском тексте:\", russian_freq)\n",
        "\n",
        "english_text = \"Natural language processing is a field of artificial intelligence. Natural language processing focuses on the interaction between computers and humans.\"\n",
        "english_freq = tokenize_text(english_text)\n",
        "print(\"\\nИсходный английский текст:\", english_text)\n",
        "print(\"Частотность слов в английском тексте:\", english_freq)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPTWlfsD2ehu"
      },
      "source": [
        "Упражнение 3: Поиск самых длинных и коротких слов. Напишите функцию, которая находит самые длинные и самые короткие слова в тексте."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hizov4xW2YhX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41a29948-32e1-4884-fb48-33d0564d28d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Русский текст: Компьютерная лингвистика является междисциплинарной областью науки, которая изучает математические и компьютерные модели естественного языка, а также его применение в системах искусственного интеллекта.\n",
            "Самые длинные русские слова: ['междисциплинарной']\n",
            "Самые короткие русские слова: ['и', 'а', 'в']\n",
            "\n",
            "Английский текст: Computational linguistics is an interdisciplinary field of science that studies mathematical and computational models of natural language and its application in artificial intelligence systems.\n",
            "Самые длинные английские слова: ['interdisciplinary']\n",
            "Самые короткие английские слова: ['is', 'an', 'of', 'in']\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "def find_longest_shortest (text):\n",
        "    text = text.lower()\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    normalized_text = text.translate(translator)\n",
        "    words = normalized_text.split()\n",
        "\n",
        "    longest_words = []\n",
        "    shortest_words = []\n",
        "\n",
        "    min_len = len(words[0])\n",
        "    max_len = len(words[0])\n",
        "\n",
        "    for word in words:\n",
        "        length = len(word)\n",
        "\n",
        "        if length > max_len:\n",
        "            max_len = length\n",
        "            longest_words = [word]\n",
        "        elif length == max_len:\n",
        "            if word not in longest_words:\n",
        "                longest_words.append(word)\n",
        "\n",
        "        if length < min_len:\n",
        "            min_len = length\n",
        "            shortest_words = [word]\n",
        "        elif length == min_len:\n",
        "            if word not in shortest_words:\n",
        "                shortest_words.append(word)\n",
        "\n",
        "    return longest_words, shortest_words\n",
        "\n",
        "sample_text = \"Компьютерная лингвистика является междисциплинарной областью науки, которая изучает математические и компьютерные модели естественного языка, а также его применение в системах искусственного интеллекта.\"\n",
        "longest_russian, shortest_russian = find_longest_shortest(sample_text)\n",
        "print(\"Русский текст:\", sample_text)\n",
        "print(\"Самые длинные русские слова:\", longest_russian)\n",
        "print(\"Самые короткие русские слова:\", shortest_russian)\n",
        "\n",
        "\n",
        "english_text = \"Computational linguistics is an interdisciplinary field of science that studies mathematical and computational models of natural language and its application in artificial intelligence systems.\"\n",
        "longest_english, shortest_english = find_longest_shortest(english_text)\n",
        "print(\"\\nАнглийский текст:\", english_text)\n",
        "print(\"Самые длинные английские слова:\", longest_english)\n",
        "print(\"Самые короткие английские слова:\", shortest_english)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wtQ6vmk922D6"
      },
      "source": [
        "Упражнение 4: Поиск и подсчет определенных паттернов. Напишите функцию, которая находит и подсчитывает слова, начинающиеся с определенной буквы или содержащие определенную последовательность букв."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pv0AYXVp23vc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "275f6b94-79b2-42b5-9c1e-03c45cea6bd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный текст: Компьютерная лингвистика изучает методы обработки текста. Математические модели и компьютерные алгоритмы используются для анализа естественных языков.\n",
            "Слова, начинающиеся с буквы 'к': ['компьютерная', 'компьютерные']\n",
            "Всего слов, начинающихся с буквы 'к': 2\n"
          ]
        }
      ],
      "source": [
        "# Поиск слов, начинающихся с 'к'\n",
        "\n",
        "import string\n",
        "def find_words_begining_with_k(text):\n",
        "    text = text.lower()\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    normalized_text = text.translate(translator)\n",
        "    words = normalized_text.split()\n",
        "\n",
        "    k_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if word.startswith('к'):\n",
        "                k_words.append(word)\n",
        "\n",
        "    return k_words\n",
        "\n",
        "sample_text = \"Компьютерная лингвистика изучает методы обработки текста. Математические модели и компьютерные алгоритмы используются для анализа естественных языков.\"\n",
        "k_words = find_words_begining_with_k(sample_text)\n",
        "print(\"Исходный текст:\", sample_text)\n",
        "print(\"Слова, начинающиеся с буквы 'к':\", k_words)\n",
        "print(\"Всего слов, начинающихся с буквы 'к':\", len(k_words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1i4Yjoum26nz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aec78f2a-05ef-4878-c32c-664aa9a2cd8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный текст: Computational linguistics studies methods of text processing. Mathematical models and computer algorithms are used to analyze natural languages.\n",
            "Слова, содержащие 'ing': ['linguistics', 'processing']\n",
            "Всего слов, содержащих 'ing': 2\n"
          ]
        }
      ],
      "source": [
        "# Поиск слов, содержащих 'ing'\n",
        "\n",
        "import string\n",
        "def find_words_containing_ing(text):\n",
        "    text = text.lower()\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    normalized_text = text.translate(translator)\n",
        "    words = normalized_text.split()\n",
        "\n",
        "    ing_words = []\n",
        "\n",
        "    for word in words:\n",
        "        if 'ing' in word:\n",
        "                ing_words.append(word)\n",
        "\n",
        "    return ing_words\n",
        "\n",
        "english_text = \"Computational linguistics studies methods of text processing. Mathematical models and computer algorithms are used to analyze natural languages.\"\n",
        "ing_words = find_words_containing_ing(english_text)\n",
        "print(\"Исходный текст:\", english_text)\n",
        "print(\"Слова, содержащие 'ing':\", ing_words)\n",
        "print(\"Всего слов, содержащих 'ing':\", len(ing_words))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anDhdjLG3M1A"
      },
      "source": [
        "Упражнение 5: Анализ предложений в тексте. Напишите функцию, которая анализирует текст на уровне предложений, подсчитывая:\n",
        "\n",
        "1. Количество предложений\n",
        "2. Среднюю длину предложения (в словах)\n",
        "3. Самое длинное и самое короткое предложение\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def analyze_sentences(text):\n",
        "\n",
        "    for end_mark in ['.', '!', '?']:\n",
        "        text = text.replace(end_mark, f'{end_mark}SENTENCE_END')\n",
        "    sentences = text.split('SENTENCE_END')\n",
        "    cleaned_sentences = [sentence.strip() for sentence in sentences if sentence.strip()]\n",
        "\n",
        "    sentences_num = len(cleaned_sentences)\n",
        "    words_in_sentence = [len(sentence.split()) for sentence in cleaned_sentences]\n",
        "    average_length = sum(words_in_sentence) / sentences_num\n",
        "\n",
        "    longest_sentence = max(cleaned_sentences, key=len)\n",
        "    shortest_sentence = min(cleaned_sentences, key=len)\n",
        "\n",
        "    return sentences_num, average_length, longest_sentence, shortest_sentence\n",
        "\n",
        "\n",
        "sample_text = \"\"\"Компьютерная лингвистика — это междисциплинарная область науки.\n",
        "Она изучает математические и компьютерные модели естественного языка.\n",
        "Методы компьютерной лингвистики применяются для решения различных задач, таких как машинный перевод, автоматическое реферирование и информационный поиск.\n",
        "Современные алгоритмы позволяют анализировать большие объемы текстов.\"\"\"\n",
        "\n",
        "sentences_num, average_length, longest_sentence, shortest_sentence = analyze_sentences(sample_text)\n",
        "print(\"Результаты анализа предложений:\")\n",
        "print(f\"Количество предложений: {sentences_num}\")\n",
        "print(f\"Средняя длина предложения (в словах): {average_length}\")\n",
        "print(f\"Самое длинное предложение: {longest_sentence}\")\n",
        "print(f\"Самое короткое предложение: {shortest_sentence}\")"
      ],
      "metadata": {
        "id": "yQP3tGPPUaDS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ff11325-d356-4281-e786-0f4736e18887"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результаты анализа предложений:\n",
            "Количество предложений: 4\n",
            "Средняя длина предложения (в словах): 9.75\n",
            "Самое длинное предложение: Методы компьютерной лингвистики применяются для решения различных задач, таких как машинный перевод, автоматическое реферирование и информационный поиск.\n",
            "Самое короткое предложение: Компьютерная лингвистика — это междисциплинарная область науки.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "english_text = \"\"\"Computational linguistics is an interdisciplinary field of science.\n",
        "It studies mathematical and computational models of natural language.\n",
        "Methods of computational linguistics are applied to solve various tasks such as machine translation, automatic summarization, and information retrieval.\n",
        "Modern algorithms allow analyzing large volumes of texts.\"\"\"\n",
        "#Анализ предложений на английском\n",
        "\n",
        "sentences_num, average_length, longest_sentence, shortest_sentence = analyze_sentences(english_text)\n",
        "\n",
        "print(\"Результаты анализа предложений на английском:\")\n",
        "print(f\"Количество предложений: {sentences_num}\")\n",
        "print(f\"Средняя длина предложения (в словах): {average_length}\")\n",
        "print(f\"Самое длинное предложение: {longest_sentence}\")\n",
        "print(f\"Самое короткое предложение: {shortest_sentence}\")"
      ],
      "metadata": {
        "id": "09QlrfTPU3ig",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39c68d34-0911-4e0a-ea54-3d7f0a39e662"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Результаты анализа предложений на английском:\n",
            "Количество предложений: 4\n",
            "Средняя длина предложения (в словах): 11.0\n",
            "Самое длинное предложение: Methods of computational linguistics are applied to solve various tasks such as machine translation, automatic summarization, and information retrieval.\n",
            "Самое короткое предложение: Modern algorithms allow analyzing large volumes of texts.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZE7TEjrM37te"
      },
      "source": [
        "**5. Домашнее задание**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJtWAqaL3-od"
      },
      "source": [
        "Напишите функцию для нормализации текста, которая:\n",
        "\n",
        "1. Приводит текст к нижнему регистру\n",
        "2. Удаляет все знаки пунктуации\n",
        "3. Заменяет все цифры на символ '#'\n",
        "4. Удаляет лишние пробелы\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def normalize_text(text):\n",
        "    text = text.lower()\n",
        "\n",
        "    text = ''.join(char for char in text if char not in string.punctuation)\n",
        "\n",
        "    text = ''.join('#' if char in string.digits else char for char in text)\n",
        "\n",
        "    text = ' '.join(text.split())\n",
        "\n",
        "    return text\n",
        "\n",
        "sample_text = \"Пример текста123, с РАЗНЫМИ символами! И 456 цифрами?!\"\n",
        "normalized_text = normalize_text(sample_text)\n",
        "print(\"Исходный текст:\", sample_text)\n",
        "print(\"Нормализованный текст:\", normalized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OEx5Dgv6OJv",
        "outputId": "fe9636db-b6e7-4e4d-91c8-05f1604aaa18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный текст: Пример текста123, с РАЗНЫМИ символами! И 456 цифрами?!\n",
            "Нормализованный текст: пример текста### с разными символами и ### цифрами\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишите функцию, которая находит и выводит все слова из текста, содержащие гласные в определенной последовательности (например, 'о' и затем 'а').\n",
        "\n"
      ],
      "metadata": {
        "id": "IE5uW5SAUHWR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def shrink(word, sequence):\n",
        "  return ''.join(char for char in word if char in sequence)\n",
        "\n",
        "def find_words_with_vowel_sequence(text, sequence):\n",
        "  text = text.lower()\n",
        "  text = ''.join(' ' if char in string.punctuation else char for char in text)\n",
        "  words = text.split()\n",
        "  return [word for word in words if sequence in shrink(word, sequence)]\n",
        "\n",
        "sample_text = \"Компьютерная лингвистика изучает методы обработки текста. Математические модели и компьютерные алгоритмы используются для анализа естественных языков. Оазис в пустыне.\"\n",
        "sequence = \"оа\"\n",
        "found_words = find_words_with_vowel_sequence(sample_text, sequence)\n",
        "print(f\"Исходный текст: {sample_text}\")\n",
        "print(f\"Слова, содержащие последовательность гласных '{sequence}': {found_words}\")\n",
        "print(f\"Всего слов, содержащих последовательность гласных '{sequence}': {len(found_words)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ponLIkNR91uw",
        "outputId": "6732428d-86e6-4296-bb94-50d13022e312"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный текст: Компьютерная лингвистика изучает методы обработки текста. Математические модели и компьютерные алгоритмы используются для анализа естественных языков. Оазис в пустыне.\n",
            "Слова, содержащие последовательность гласных 'оа': ['компьютерная', 'обработки', 'оазис']\n",
            "Всего слов, содержащих последовательность гласных 'оа': 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создайте функцию, которая:\n",
        "\n",
        "1. Токенизирует текст\n",
        "2. Отбирает только слова длиной более 4 символов\n",
        "3. Сортирует их по алфавиту\n",
        "4. Возвращает первые 10 слов\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fEoMtXcVVAJA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "def process_text(text):\n",
        "    translator = str.maketrans('', '', string.punctuation)\n",
        "    text = text.lower()\n",
        "    cleaned_text = text.translate(translator)\n",
        "    words = cleaned_text.split()\n",
        "\n",
        "    words_over_4 = [word for word in words if len(word) > 4]\n",
        "\n",
        "    words_over_4.sort()\n",
        "\n",
        "    return words_over_4[:10]\n",
        "\n",
        "sample_text = \"Компьютерная лингвистика изучает методы обработки текста. Математические модели и компьютерные алгоритмы используются для анализа естественных языков.\"\n",
        "print(\"Исходный текст:\", sample_text)\n",
        "print(\"Первые 10 слов > 4 символов:\", process_text(sample_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5JECWK57HsWU",
        "outputId": "bdd0e111-6940-4748-c7b6-ce332db71bef"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Исходный текст: Компьютерная лингвистика изучает методы обработки текста. Математические модели и компьютерные алгоритмы используются для анализа естественных языков.\n",
            "Первые 10 слов > 4 символов: ['алгоритмы', 'анализа', 'естественных', 'изучает', 'используются', 'компьютерная', 'компьютерные', 'лингвистика', 'математические', 'методы']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишите функцию для анализа частотности символов в тексте, которая возвращает 5 самых часто встречающихся символов и их количество.\n",
        "\n"
      ],
      "metadata": {
        "id": "Tsx1YncpVO2A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def find_char_freq(text):\n",
        "  char_freq = {}\n",
        "  for char in text:\n",
        "    if char in char_freq:\n",
        "      char_freq[char] += 1\n",
        "    else:\n",
        "      char_freq[char] = 1\n",
        "  return sorted(char_freq.items(), key=lambda x: x[1], reverse=True)[:5]\n",
        "\n",
        "sample_text = \"Компьютерная лингвистика изучает методы обработки текста. Математические модели и компьютерные алгоритмы используются для анализа естественных языков.\"\n",
        "print(\"5 самых часто встречающихся символов:\", find_char_freq(sample_text))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UlekiFPGgV7k",
        "outputId": "24544430-921a-46fe-d315-4c4dfd1581b6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5 самых часто встречающихся символов: [(' ', 15), ('т', 14), ('е', 13), ('и', 12), ('а', 11)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Напишите программу, которая разделяет текст на параграфы (по двойному переносу строки), а затем подсчитывает для каждого параграфа: количество предложений, количество слов, среднюю длину слова"
      ],
      "metadata": {
        "id": "uLIbIuu2VTsS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def analyze_paragraphs(text):\n",
        "\n",
        "    paragraphs = text.split('\\n\\n')\n",
        "    results = []\n",
        "\n",
        "    for i, paragraph in enumerate(paragraphs):\n",
        "        sentences = []\n",
        "        current_sentence = \"\"\n",
        "        for char in paragraph:\n",
        "            current_sentence += char\n",
        "            if char in ['.', '!', '?']:\n",
        "                sentences.append(current_sentence.strip())\n",
        "                current_sentence = \"\"\n",
        "        if current_sentence.strip():\n",
        "            sentences.append(current_sentence.strip())\n",
        "\n",
        "\n",
        "        sentences = [s for s in sentences if s]\n",
        "        sentences_num = len(sentences)\n",
        "\n",
        "        words = []\n",
        "        translator = str.maketrans('', '', string.punctuation + string.digits)\n",
        "        cleaned_paragraph = paragraph.translate(translator).lower()\n",
        "        paragraph_words = cleaned_paragraph.split()\n",
        "        words = [word for word in paragraph_words if word]\n",
        "\n",
        "        words_num = len(words)\n",
        "\n",
        "        average_word_length = sum(len(word) for word in words) / words_num if words_num > 0 else 0\n",
        "\n",
        "        results.append({\n",
        "                'sentences_num': sentences_num,\n",
        "                'words_num': words_num,\n",
        "                'average_word_length': round(average_word_length, 2)\n",
        "        })\n",
        "\n",
        "    return results\n",
        "\n",
        "sample_text = \"\"\"Каждый год количество информации в сети увеличивается в два раза. Постоянно появляются новые, редактируются имеющиеся, копируются, отправляются и сохраняются целые терабайты данных. И лишь 20% всей информации защищено.\n",
        "\n",
        "Это не только развлекательный и познавательный контент, но и критические данные, которые хранятся в информационных системах организаций, компаний и структур. За такими системами закрепляют статус субъекта критической информационной инфраструктуры.\n",
        "\n",
        "Исследование Национального центра по компьютерным инцидентам выявило, что за 2018 год объекты КИИ подвергались атакам более 4 млрд раз. И это только обнаруженные. \"\"\"\n",
        "\n",
        "results = analyze_paragraphs(sample_text)\n",
        "for i, result in enumerate(results, 1):\n",
        "    print(f\"Параграф {i}:\")\n",
        "    print(f\"Количество предложений в параграфе: {result['sentences_num']}\")\n",
        "    print(f\"Количество слов в параграфе: {result['words_num']}\")\n",
        "    print(f\"Средняя длина слова в каждом параграфе: {result['average_word_length']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jaPFpr3n0jb",
        "outputId": "a9f4ce73-9897-438b-a341-c3e6c2f92b7b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Параграф 1:\n",
            "Количество предложений в параграфе: 3\n",
            "Количество слов в параграфе: 27\n",
            "Средняя длина слова в каждом параграфе: 6.74\n",
            "Параграф 2:\n",
            "Количество предложений в параграфе: 2\n",
            "Количество слов в параграфе: 29\n",
            "Средняя длина слова в каждом параграфе: 7.38\n",
            "Параграф 3:\n",
            "Количество предложений в параграфе: 2\n",
            "Количество слов в параграфе: 21\n",
            "Средняя длина слова в каждом параграфе: 6.29\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}