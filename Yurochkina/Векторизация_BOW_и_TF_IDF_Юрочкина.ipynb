{"cells":[{"cell_type":"markdown","metadata":{"id":"owKq2QMu-_V-"},"source":["Эта тетрадка содержит примеры и упражнения по двум основным методам векторизации текста: Bag of Words (мешок слов) и TF-IDF (Term Frequency-Inverse Document Frequency)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C-tsQpvKAdW9"},"outputs":[],"source":["import re\n","import pandas as pd"]},{"cell_type":"markdown","metadata":{"id":"WEJQsdB__X3v"},"source":["**Часть 1: Исходные данные**"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"d4n2kaiB-y9C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1768825810834,"user_tz":-600,"elapsed":15,"user":{"displayName":"Ксения Лисовицкая","userId":"14321374281072080389"}},"outputId":"a9ced30d-d18b-4801-b73c-dae7720cd07c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Документ 1: Машинное обучение - это подраздел искусственного интеллекта.\n","Документ 2: Нейронные сети широко используются в машинном обучении.\n","Документ 3: Глубокое обучение основано на многослойных нейронных сетях.\n","Документ 4: Искусственный интеллект имитирует когнитивные функции человека.\n","Документ 5: Компьютерное зрение и обработка языка - примеры применения ИИ.\n"]}],"source":["# Наш корпус документов\n","documents = [\n","    \"Машинное обучение - это подраздел искусственного интеллекта.\",\n","    \"Нейронные сети широко используются в машинном обучении.\",\n","    \"Глубокое обучение основано на многослойных нейронных сетях.\",\n","    \"Искусственный интеллект имитирует когнитивные функции человека.\",\n","    \"Компьютерное зрение и обработка языка - примеры применения ИИ.\"\n","]\n","\n","# Вывод документов с номерами\n","for i, doc in enumerate(documents, 1):\n","    print(f\"Документ {i}: {doc}\")"]},{"cell_type":"markdown","metadata":{"id":"tApzmP2y_80E"},"source":["**Часть 2: Предобработка**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h8f1OVNaAAeP"},"outputs":[],"source":["for i in range(len(documents)):\n","    # Приведение к нижнему регистру\n","    documents[i] = documents[i].lower()\n","    # Удаление пунктуации\n","    documents[i] = re.sub(r'[^\\w\\s]', '', documents[i])\n","\n","  # Вывод предобработанных документов\n","print(\"Предобработанные документы:\")\n","for i, doc in enumerate(documents, 1):\n","    print(f\"Документ {i}: {doc}\")"]},{"cell_type":"markdown","metadata":{"id":"XakwSM_Z_dqJ"},"source":["**Часть 3: Модель Bag of Words (мешок слов)**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pdp6lFOB3mC"},"outputs":[],"source":["from sklearn.feature_extraction.text import CountVectorizer  # Для создания Bag of Words"]},{"cell_type":"markdown","metadata":{"id":"PHP7yxKQCEpb"},"source":["3.1 Создание матрицы Bag of Words"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"scdI5kc4B4-E","colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"status":"error","timestamp":1768825830181,"user_tz":-600,"elapsed":15,"user":{"displayName":"Ксения Лисовицкая","userId":"14321374281072080389"}},"outputId":"2f79acee-5807-44f5-e02d-c812d2a0614c"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'CountVectorizer' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-2222486935.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Создание векторизатора\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcount_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Обучение векторизатора и преобразование документов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mbow_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"]}],"source":["# Создание векторизатора\n","count_vectorizer = CountVectorizer()\n","\n","# Обучение векторизатора и преобразование документов\n","bow_matrix = count_vectorizer.fit_transform(documents)\n","\n","# Получение списка фичей (слов)\n","feature_names = count_vectorizer.get_feature_names_out()\n","\n","# Преобразование разреженной матрицы в плотную для наглядности\n","bow_df = pd.DataFrame(\n","    bow_matrix.toarray(),\n","    columns=feature_names,\n","    index=[f'Документ {i+1}' for i in range(len(documents))]\n",")\n","\n","# Вывод матрицы Bag of Words\n","print(\"Матрица Bag of Words:\")\n","print(bow_df)"]},{"cell_type":"markdown","metadata":{"id":"PMK9JL-1C4Dn"},"source":["Получение списка фичей (слов)\n","\n","feature_names = count_vectorizer.get_feature_names_out()\n","Что происходит:\n","Этот шаг извлекает из обученного CountVectorizer все уникальные слова (или n-граммы), которые были использованы при создании матрицы Bag of Words.\n","\n","Зачем это нужно:\n","* Интерпретация результатов: Без этого шага у нас была бы только числовая матрица, но мы не знали бы, какой столбец соответствует какому слову.\n","* Понимание словаря: Метод get_feature_names_out() возвращает список всех уникальных терминов, которые векторизатор извлек из документов и включил в свой словарь.\n","* Подготовка к визуализации: Имена признаков необходимы для создания понятной таблицы с метками строк и столбцов."]},{"cell_type":"markdown","metadata":{"id":"_MtVs8JuDTt6"},"source":["**Часть 4: Модель TF-IDF**"]},{"cell_type":"markdown","metadata":{"id":"TyAEZkC_Dmrx"},"source":["4.1 Создание матрицы TF-IDF"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUpUVp_iD2xf"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"nauTaaSvDonR","colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"status":"error","timestamp":1768825835890,"user_tz":-600,"elapsed":6,"user":{"displayName":"Ксения Лисовицкая","userId":"14321374281072080389"}},"outputId":"b4388164-508f-4b36-eed6-39b85da79f98"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'TfidfVectorizer' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-1567020677.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Создание TF-IDF векторизатора\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtfidf_vectorizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Обучение векторизатора и преобразование документов\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtfidf_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"]}],"source":["# Создание TF-IDF векторизатора\n","tfidf_vectorizer = TfidfVectorizer()\n","\n","# Обучение векторизатора и преобразование документов\n","tfidf_matrix = tfidf_vectorizer.fit_transform(documents)\n","\n","# Преобразование в DataFrame\n","tfidf_df = pd.DataFrame(\n","    tfidf_matrix.toarray(),\n","    columns=tfidf_vectorizer.get_feature_names_out(),\n","    index=[f'Документ {i+1}' for i in range(len(documents))]\n",")\n","\n","# Вывод матрицы TF-IDF\n","print(\"Матрица TF-IDF:\")\n","print(tfidf_df)"]},{"cell_type":"markdown","metadata":{"id":"keRydTjVHBdq"},"source":["**Часть 5. Сравнение результатов**"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"SjuAChaKPomZ","executionInfo":{"status":"ok","timestamp":1768825841620,"user_tz":-600,"elapsed":10,"user":{"displayName":"Ксения Лисовицкая","userId":"14321374281072080389"}}},"outputs":[],"source":["import numpy as np"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"GAbzPK8YL_KR","colab":{"base_uri":"https://localhost:8080/","height":207},"executionInfo":{"status":"error","timestamp":1768825843328,"user_tz":-600,"elapsed":22,"user":{"displayName":"Ксения Лисовицкая","userId":"14321374281072080389"}},"outputId":"1837aab6-02c5-4882-a823-bec3a711a850"},"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'bow_matrix' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-301792332.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Суммируем значения по всем документам для BOW\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# Для BOW просто суммируем частоты слов по всем документам\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mbow_sum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbow_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Создаем словарь слово -> суммарная частота\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'bow_matrix' is not defined"]}],"source":["# Суммируем значения по всем документам для BOW\n","# Для BOW просто суммируем частоты слов по всем документам\n","bow_sum = np.sum(bow_matrix.toarray(), axis=0)\n","\n","# Создаем словарь слово -> суммарная частота\n","word_bow_dict = dict(zip(feature_names, bow_sum))\n","\n","# Находим топ-3 слова по BOW (самые частотные в коллекции)\n","top_bow_words = sorted(word_bow_dict.items(), key=lambda x: x[1], reverse=True)[:3]\n","\n","print(\"=== Топ-3 слова по всей коллекции ===\\n\")\n","print(\"Топ-3 слова по BOW (самые частые в коллекции):\")\n","for word, count in top_bow_words:\n","    print(f\"- {word}: {count} раз\")\n","\n","# Для TF-IDF нужно суммировать значения по всем документам\n","tfidf_sum = np.sum(tfidf_matrix.toarray(), axis=0)\n","\n","# Создаем словарь слово -> суммарный TF-IDF вес\n","word_tfidf_dict = dict(zip(feature_names, tfidf_sum))\n","\n","# Находим топ-3 слова по TF-IDF (с наибольшим суммарным весом по всей коллекции)\n","top_tfidf_words = sorted(word_tfidf_dict.items(), key=lambda x: x[1], reverse=True)[:3]\n","\n","print(\"\\nТоп-3 слова по TF-IDF (с наибольшим весом по всей коллекции):\")\n","for word, score in top_tfidf_words:\n","    print(f\"- {word}: {score:.4f}\")\n","\n","# Показываем разницу между списками\n","print(\"\\nСравнение топ-3 слов:\")\n","bow_words = [word for word, _ in top_bow_words]\n","tfidf_words = [word for word, _ in top_tfidf_words]\n","\n","common_words = set(bow_words) & set(tfidf_words)\n","bow_only = set(bow_words) - common_words\n","tfidf_only = set(tfidf_words) - common_words\n","\n","if common_words:\n","    print(f\"Общие слова в обоих топ-3: {', '.join(common_words)}\")\n","if bow_only:\n","    print(f\"Только в BOW топ-3: {', '.join(bow_only)}\")\n","if tfidf_only:\n","    print(f\"Только в TF-IDF топ-3: {', '.join(tfidf_only)}\")"]},{"cell_type":"markdown","metadata":{"id":"ycGpAdTzQHs_"},"source":["**Самостоятельная работа**"]},{"cell_type":"markdown","metadata":{"id":"pLOsSo-xQO_i"},"source":["ЗАДАНИЕ:\n","1. Предобработайте эти документы (удалите стоп-слова, приведите к нижнему регистру)\n","2. Создайте матрицу Bag of Words\n","3. Создайте матрицу TF-IDF\n","4. Найдите и выведите топ-3 важных слова для каждого документа по Bag of Words\n","5. Найдите и выведите топ-3 важных слова для каждого документа по TF-IDF\n","6. Проанализируйте разницу между результатами и объясните её\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"csxiQZNhQWHb"},"outputs":[],"source":["# Создаем коллекцию документов\n","exercise_documents = [\n","    \"Япония поражает сочетанием древних традиций и футуристических технологий. Токио с его небоскребами и неоновыми огнями соседствует с тихими храмами и садами. Весной цветение сакуры превращает страну в розовое облако. Японская кухня, от суши до рамена, предлагает уникальные вкусовые ощущения. Синкансэны позволяют комфортно перемещаться между городами.\",\n","\n","    \"Исландия — страна потрясающих природных контрастов. Ледники соседствуют с действующими вулканами, а горячие гейзеры бьют среди снежных равнин. Северное сияние зимой и незаходящее солнце летом создают ощущение другой планеты. Голубая лагуна с ее геотермальными водами — идеальное место для расслабления после долгих пеших походов по национальным паркам.\",\n","\n","    \"Таиланд привлекает путешественников белоснежными пляжами и кристально чистой водой. Острова Пхукет и Самуи предлагают роскошные курорты и активный отдых. Бангкок поражает контрастами: золотые храмы соседствуют с оживленными рынками и современными торговыми центрами. Тайская кухня с ее острыми ароматами и экзотическими фруктами — отдельное гастрономическое путешествие.\",\n","\n","    \"Италия — настоящий музей под открытым небом. Рим хранит наследие древней империи в Колизее и Форуме. Венеция очаровывает каналами и гондолами. Флоренция — сокровищница искусства эпохи Возрождения. Побережье Амальфи и озеро Комо предлагают живописные пейзажи. Итальянская кухня, от пасты до джелато, заслуженно считается одной из лучших в мире.\",\n","\n","    \"Перу хранит тайны древних цивилизаций. Мачу-Пикчу, затерянный город инков, привлекает туристов со всего мира. Линии Наска, гигантские рисунки на плато, до сих пор остаются загадкой. Озеро Титикака поражает своими плавучими островами, на которых живут местные племена. Перуанская кухня, с ее свежими морепродуктами и разнообразием картофеля, переживает всемирное признание.\",\n","\n","    \"Марокко — это калейдоскоп красок и ароматов. Медины Феса и Марракеша с их узкими улочками и шумными базарами погружают в атмосферу арабских сказок. Пустыня Сахара предлагает незабываемые ночи под звездами в берберских лагерях. Атласские горы привлекают любителей трекинга. Марокканская кухня славится тажинами и кус-кусом, приправленными экзотическими специями.\",\n","\n","    \"Новая Зеландия — рай для любителей природы и активного отдыха. Фьорды Милфорд-Саунд, ледники Южных Альп и гейзеры Роторуа демонстрируют разнообразие ландшафтов. Хоббитон, декорации из фильмов «Властелин колец», привлекают поклонников Толкина. Маори, коренное население, сохраняет свою уникальную культуру. Адреналиновые развлечения, от банджи-джампинга до рафтинга, доступны по всей стране.\",\n","\n","    \"Кения предлагает классическое африканское сафари. Масаи-Мара, Амбосели и Цаво — национальные парки, где можно увидеть «большую пятерку» африканских животных в их естественной среде. Ежегодная миграция антилоп гну — одно из самых впечатляющих природных зрелищ. Пляжи Момбасы с коралловыми рифами идеальны для дайвинга и снорклинга. Племена масаи и самбуру сохраняют традиционный образ жизни.\",\n","\n","    \"Вьетнам сочетает богатую историю и динамичное настоящее. Бухта Халонг с ее карстовыми островами — природное чудо. Хойан очаровывает древними улочками и бумажными фонариками. Дельта Меконга предлагает возможность познакомиться с сельской жизнью. Вьетнамская кухня, от фо до свежих спринг-роллов, покоряет своей свежестью. Система туннелей Ку-Чи напоминает о недавней войне.\",\n","\n","    \"Антарктида — последний неосвоенный континент, привлекающий самых отважных путешественников. Круизы из Ушуаи позволяют увидеть айсберги, пингвинов и китов. Пересечение пролива Дрейка — настоящее испытание для морских путешественников. Исследовательские станции разных стран ведут научную работу в суровых условиях. Полуночное солнце летом создает сюрреалистичные пейзажи ледяной пустыни.\"\n","]"]},{"cell_type":"code","source":["\n","import sys\n","import subprocess\n","import importlib\n","\n","def install_if_needed(package_name, import_name=None):\n","    \"\"\"Устанавливает пакет, если он не установлен\"\"\"\n","    if import_name is None:\n","        import_name = package_name\n","\n","    try:\n","        importlib.import_module(import_name)\n","        print(f\"✓ {package_name} уже установлен\")\n","        return True\n","    except ImportError:\n","        print(f\"Установка {package_name}...\")\n","        try:\n","            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package_name])\n","            print(f\"✓ {package_name} успешно установлен\")\n","            return True\n","        except subprocess.CalledProcessError:\n","            print(f\"✗ Не удалось установить {package_name}\")\n","            return False\n","\n","install_if_needed(\"scikit-learn\")\n","install_if_needed(\"nltk\")\n","\n","\n","import re\n","import numpy as np\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","\n","exercise_documents = [\n","    \"Машинное обучение — это раздел искусственного интеллекта, изучающий алгоритмы, способные обучаться на данных.\",\n","    \"Глубокое обучение является подразделом машинного обучения, использующим нейронные сети с множеством слоев.\",\n","    \"Нейронные сети — это вычислительные системы, вдохновленные биологическими нейронными сетями мозга животных.\",\n","    \"Обработка естественного языка (NLP) — это область искусственного интеллекта, изучающая взаимодействие компьютеров и человеческого языка.\",\n","    \"Компьютерное зрение — это научная дисциплина, изучающая методы извлечения информации из изображений и видео.\"\n","]\n","\n","\n","import nltk\n","\n","try:\n","    nltk.download('stopwords', quiet=True)\n","    print(\"✓ Ресурс 'stopwords' успешно загружен\")\n","except Exception as e:\n","    print(f\"✗ Ошибка загрузки 'stopwords': {e}\")\n","\n","    stop_words = {'и', 'в', 'во', 'не', 'что', 'он', 'на', 'я', 'с', 'со', 'как', 'а', 'то', 'все', 'она',\n","                  'так', 'его', 'но', 'да', 'ты', 'к', 'у', 'же', 'вы', 'за', 'бы', 'по', 'только', 'ее',\n","                  'мне', 'было', 'вот', 'от', 'меня', 'еще', 'нет', 'о', 'из', 'ему', 'теперь', 'когда',\n","                  'даже', 'ну', 'ли', 'если', 'уже', 'или', 'ни', 'быть', 'был', 'него', 'до', 'вас',\n","                  'нибудь', 'опять', 'уж', 'вам', 'ведь', 'там', 'потом', 'себя', 'ничего', 'ей', 'может',\n","                  'они', 'тут', 'где', 'есть', 'надо', 'ней', 'для', 'мы', 'тебя', 'их', 'чем', 'была',\n","                  'сам', 'чтоб', 'без', 'будто', 'чего', 'раз', 'тоже', 'себе', 'под', 'будет', 'ж', 'тогда',\n","                  'кто', 'этот', 'того', 'потому', 'этого', 'какой', 'совсем', 'ним', 'здесь', 'этом',\n","                  'один', 'почти', 'мой', 'тем', 'чтобы', 'нее', 'сейчас', 'были', 'куда', 'зачем', 'всех',\n","                  'никогда', 'можно', 'при', 'наконец', 'два', 'об', 'другой', 'хоть', 'после', 'над',\n","                  'больше', 'тот', 'через', 'эти', 'нас', 'про', 'всего', 'них', 'какая', 'много', 'разве',\n","                  'три', 'эту', 'моя', 'впрочем', 'хорошо', 'свою', 'этой', 'перед', 'иногда', 'лучше',\n","                  'чуть', 'том', 'нельзя', 'такой', 'им', 'более', 'всегда', 'конечно', 'всю', 'между'}\n","else:\n","\n","    from nltk.corpus import stopwords\n","    stop_words = set(stopwords.words('russian'))\n","\n","print(f\"\\nИспользуется {len(stop_words)} стоп-слов\")\n","\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"ПРЕДОБРАБОТКА ТЕКСТА\")\n","print(\"=\"*50)\n","\n","processed_docs = []\n","for i in range(len(exercise_documents)):\n","\n","    doc_lower = exercise_documents[i].lower()\n","\n","\n","    doc_clean = re.sub(r'[^\\w\\s]', '', doc_lower)\n","\n","\n","    words = doc_clean.split()\n","    filtered_words = [word for word in words if word not in stop_words]\n","    processed_doc = \" \".join(filtered_words)\n","    processed_docs.append(processed_doc)\n","\n","    print(f\"\\nДокумент {i+1}:\")\n","    print(f\"  Оригинал: {exercise_documents[i][:50]}...\")\n","    print(f\"  После обработки: {processed_doc[:50]}...\")\n","\n","\n","exercise_documents = processed_docs\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"АНАЛИЗ BAG OF WORDS\")\n","print(\"=\"*50)\n","\n","\n","count_vectorizer = CountVectorizer()\n","bow_matrix = count_vectorizer.fit_transform(exercise_documents)\n","bow_feature_names = count_vectorizer.get_feature_names_out()\n","\n","print(f\"\\nСловарь содержит {len(bow_feature_names)} уникальных слов\")\n","print(\"Слова в словаре:\", bow_feature_names[:10], \"...\" if len(bow_feature_names) > 10 else \"\")\n","\n","print(\"\\nТоп-3 слова по Bag of Words:\\n\")\n","\n","for doc_idx in range(bow_matrix.shape[0]):\n","    bow_values = bow_matrix[doc_idx].toarray()[0]\n","    top_indices = np.argsort(bow_values)[-3:][::-1]\n","\n","    top_words = [(bow_feature_names[i], int(bow_values[i]))\n","                 for i in top_indices if bow_values[i] > 0]\n","\n","\n","    if len(top_words) < 3:\n","        all_words = [(bow_feature_names[i], int(bow_values[i]))\n","                     for i in range(len(bow_values)) if bow_values[i] > 0]\n","        all_words_sorted = sorted(all_words, key=lambda x: x[1], reverse=True)\n","        top_words = all_words_sorted[:3]\n","\n","    print(f\"Документ {doc_idx + 1}: {top_words}\")\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"АНАЛИЗ TF-IDF\")\n","print(\"=\"*50)\n","\n","\n","tfidf_vectorizer = TfidfVectorizer()\n","tfidf_matrix = tfidf_vectorizer.fit_transform(exercise_documents)\n","tfidf_feature_names = tfidf_vectorizer.get_feature_names_out()\n","\n","def tfidf_top3_words(tfidf_matrix, feature_names, top_n=3):\n","    print(f\"\\nТоп-{top_n} слова по TF-IDF:\\n\")\n","\n","    for doc_idx in range(tfidf_matrix.shape[0]):\n","        tfidf_values = tfidf_matrix[doc_idx].toarray()[0]\n","\n","\n","        non_zero_indices = np.where(tfidf_values > 0)[0]\n","\n","        if len(non_zero_indices) > 0:\n","\n","            sorted_indices = non_zero_indices[np.argsort(tfidf_values[non_zero_indices])[::-1]]\n","            top_indices = sorted_indices[:top_n]\n","\n","            top_words = [(feature_names[i], round(float(tfidf_values[i]), 3))\n","                         for i in top_indices]\n","        else:\n","            top_words = []\n","\n","\n","        if len(top_words) < top_n and len(non_zero_indices) > 0:\n","            top_words = [(feature_names[i], round(float(tfidf_values[i]), 3))\n","                         for i in non_zero_indices[:top_n]]\n","\n","        print(f\"Документ {doc_idx + 1}: {top_words}\")\n","\n","tfidf_top3_words(tfidf_matrix, tfidf_feature_names)\n","\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"СРАВНЕНИЕ BOW И TF-IDF\")\n","print(\"=\"*50)\n","\n","for doc_idx in range(len(exercise_documents)):\n","    print(f\"\\nДокумент {doc_idx + 1}:\")\n","\n","\n","    bow_values = bow_matrix[doc_idx].toarray()[0]\n","    bow_top_indices = np.argsort(bow_values)[-3:][::-1]\n","    bow_top_words = [(bow_feature_names[i], int(bow_values[i]))\n","                     for i in bow_top_indices if bow_values[i] > 0]\n","\n","\n","    tfidf_values = tfidf_matrix[doc_idx].toarray()[0]\n","    tfidf_top_indices = np.argsort(tfidf_values)[-3:][::-1]\n","    tfidf_top_words = [(tfidf_feature_names[i], round(float(tfidf_values[i]), 3))\n","                       for i in tfidf_top_indices if tfidf_values[i] > 0]\n","\n","    print(f\"  BoW:    {bow_top_words}\")\n","    print(f\"  TF-IDF: {tfidf_top_words}\")\n","\n","\n","    bow_words_set = set([word for word, _ in bow_top_words])\n","    tfidf_words_set = set([word for word, _ in tfidf_top_words])\n","    common_words = bow_words_set.intersection(tfidf_words_set)\n","\n","    if common_words:\n","        print(f\"  Общие слова в топ-3: {', '.join(common_words)}\")\n","\n","\n","print(\"\\n\" + \"=\"*50)\n","print(\"СВОДНАЯ ИНФОРМАЦИЯ\")\n","print(\"=\"*50)\n","\n","print(f\"Всего документов: {len(exercise_documents)}\")\n","print(f\"Всего уникальных слов в словаре: {len(bow_feature_names)}\")\n","\n","\n","print(\"\\nХарактеристики документов:\")\n","print(\"-\" * 60)\n","print(f\"{'Док.':<5} {'Слов (ориг.)':<15} {'Слов (очищ.)':<15} {'Уникальных слов':<15}\")\n","print(\"-\" * 60)\n","\n","for i, doc in enumerate(exercise_documents):\n","    original_words = len(re.sub(r'[^\\w\\s]', '', exercise_documents[i].lower()).split())\n","    cleaned_words = len(doc.split()) if doc else 0\n","    unique_words = len(set(doc.split())) if doc else 0\n","\n","    print(f\"{i+1:<5} {original_words:<15} {cleaned_words:<15} {unique_words:<15}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qQVJX7U0Oirg","executionInfo":{"status":"ok","timestamp":1768826418016,"user_tz":-600,"elapsed":2894,"user":{"displayName":"Ксения Лисовицкая","userId":"14321374281072080389"}},"outputId":"1c74a3ab-c44d-4c88-d136-bc3535fc9cb4"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Установка scikit-learn...\n","✓ scikit-learn успешно установлен\n","✓ nltk уже установлен\n","✓ Ресурс 'stopwords' успешно загружен\n","\n","Используется 151 стоп-слов\n","\n","==================================================\n","ПРЕДОБРАБОТКА ТЕКСТА\n","==================================================\n","\n","Документ 1:\n","  Оригинал: Машинное обучение — это раздел искусственного инте...\n","  После обработки: машинное обучение это раздел искусственного интелл...\n","\n","Документ 2:\n","  Оригинал: Глубокое обучение является подразделом машинного о...\n","  После обработки: глубокое обучение является подразделом машинного о...\n","\n","Документ 3:\n","  Оригинал: Нейронные сети — это вычислительные системы, вдохн...\n","  После обработки: нейронные сети это вычислительные системы вдохновл...\n","\n","Документ 4:\n","  Оригинал: Обработка естественного языка (NLP) — это область ...\n","  После обработки: обработка естественного языка nlp это область иску...\n","\n","Документ 5:\n","  Оригинал: Компьютерное зрение — это научная дисциплина, изуч...\n","  После обработки: компьютерное зрение это научная дисциплина изучающ...\n","\n","==================================================\n","АНАЛИЗ BAG OF WORDS\n","==================================================\n","\n","Словарь содержит 47 уникальных слов\n","Слова в словаре: ['nlp' 'алгоритмы' 'биологическими' 'вдохновленные' 'взаимодействие'\n"," 'видео' 'вычислительные' 'глубокое' 'данных' 'дисциплина'] ...\n","\n","Топ-3 слова по Bag of Words:\n","\n","Документ 1: [('это', 1), ('способные', 1), ('раздел', 1)]\n","Документ 2: [('является', 1), ('слоев', 1), ('сети', 1)]\n","Документ 3: [('это', 1), ('системы', 1), ('сетями', 1)]\n","Документ 4: [('языка', 2), ('это', 1), ('человеческого', 1)]\n","Документ 5: [('это', 1), ('извлечения', 1), ('зрение', 1)]\n","\n","==================================================\n","АНАЛИЗ TF-IDF\n","==================================================\n","\n","Топ-3 слова по TF-IDF:\n","\n","Документ 1: [('способные', 0.328), ('раздел', 0.328), ('обучаться', 0.328)]\n","Документ 2: [('является', 0.317), ('слоев', 0.317), ('подразделом', 0.317)]\n","Документ 3: [('системы', 0.322), ('сетями', 0.322), ('нейронными', 0.322)]\n","Документ 4: [('языка', 0.549), ('человеческого', 0.275), ('обработка', 0.275)]\n","Документ 5: [('научная', 0.317), ('методы', 0.317), ('компьютерное', 0.317)]\n","\n","==================================================\n","СРАВНЕНИЕ BOW И TF-IDF\n","==================================================\n","\n","Документ 1:\n","  BoW:    [('это', 1), ('способные', 1), ('раздел', 1)]\n","  TF-IDF: [('способные', 0.328), ('обучаться', 0.328), ('раздел', 0.328)]\n","  Общие слова в топ-3: раздел, способные\n","\n","Документ 2:\n","  BoW:    [('является', 1), ('слоев', 1), ('сети', 1)]\n","  TF-IDF: [('является', 0.317), ('слоев', 0.317), ('подразделом', 0.317)]\n","  Общие слова в топ-3: является, слоев\n","\n","Документ 3:\n","  BoW:    [('это', 1), ('системы', 1), ('сетями', 1)]\n","  TF-IDF: [('системы', 0.322), ('сетями', 0.322), ('вычислительные', 0.322)]\n","  Общие слова в топ-3: сетями, системы\n","\n","Документ 4:\n","  BoW:    [('языка', 2), ('это', 1), ('человеческого', 1)]\n","  TF-IDF: [('языка', 0.549), ('человеческого', 0.275), ('обработка', 0.275)]\n","  Общие слова в топ-3: человеческого, языка\n","\n","Документ 5:\n","  BoW:    [('это', 1), ('извлечения', 1), ('зрение', 1)]\n","  TF-IDF: [('извлечения', 0.317), ('зрение', 0.317), ('дисциплина', 0.317)]\n","  Общие слова в топ-3: зрение, извлечения\n","\n","==================================================\n","СВОДНАЯ ИНФОРМАЦИЯ\n","==================================================\n","Всего документов: 5\n","Всего уникальных слов в словаре: 47\n","\n","Характеристики документов:\n","------------------------------------------------------------\n","Док.  Слов (ориг.)    Слов (очищ.)    Уникальных слов\n","------------------------------------------------------------\n","1     11              11              11             \n","2     11              11              11             \n","3     11              11              11             \n","4     13              13              12             \n","5     11              11              11             \n"]}]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.13.2"}},"nbformat":4,"nbformat_minor":0}